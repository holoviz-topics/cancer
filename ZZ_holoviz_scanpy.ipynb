{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1990713-5968-4fc7-aeb6-5a842606fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import pooch\n",
    "\n",
    "from hv_cancer_modules import DotPlot, UMAPPlot\n",
    "import holoviews as hv \n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161629d6-b1b6-4faa-8bca-01a841e0ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.set_figure_params(dpi=50, facecolor=\"white\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3211b168-0575-43fa-945c-405ee9438098",
   "metadata": {},
   "source": [
    "The data used in this basic preprocessing and clustering tutorial was collected from bone marrow mononuclear cells of healthy human donors and was part of [openproblem's NeurIPS 2021 benchmarking dataset](https://openproblems.bio/competitions/neurips_2021/) {cite}`Luecken2021`. The samples used in this tutorial were measured using the 10X Multiome Gene Expression and Chromatin Accessability kit. \n",
    "\n",
    "\n",
    "We are reading in the count matrix into an [AnnData](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/getting-started.html) object, which holds many slots for annotations and different representations of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0448e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_DATA = pooch.create(\n",
    "    path=pooch.os_cache(\"scverse_tutorials\"),\n",
    "    base_url=\"doi:10.6084/m9.figshare.22716739.v1/\",\n",
    ")\n",
    "EXAMPLE_DATA.load_registry_from_doi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdf7f10-e9b9-4929-a7e2-7ac373d769d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "samples = {\n",
    "    \"s1d1\": \"s1d1_filtered_feature_bc_matrix.h5\",\n",
    "    \"s1d3\": \"s1d3_filtered_feature_bc_matrix.h5\",\n",
    "}\n",
    "adatas = {}\n",
    "\n",
    "for sample_id, filename in samples.items():\n",
    "    path = EXAMPLE_DATA.fetch(filename)\n",
    "    sample_adata = sc.read_10x_h5(path)\n",
    "    sample_adata.var_names_make_unique()\n",
    "    adatas[sample_id] = sample_adata\n",
    "\n",
    "adata = ad.concat(adatas, label=\"sample\")\n",
    "adata.obs_names_make_unique()\n",
    "print(adata.obs[\"sample\"].value_counts())\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c673fe14-df28-4d53-abf6-3a852040e571",
   "metadata": {},
   "source": [
    "The data contains ~8,000 cells per sample and 36,601 measured genes. We'll now investigate these with a basic preprocessing and clustering workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e306dde3-b587-4561-b5ec-e8a2ac5e2c13",
   "metadata": {},
   "source": [
    "## Quality Control"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd32b625-7f24-4b9c-9564-dd97c57dc1b2",
   "metadata": {},
   "source": [
    "The scanpy function {func}`~scanpy.pp.calculate_qc_metrics` calculates common quality control (QC) metrics, which are largely based on `calculateQCMetrics` from scater {cite}`McCarthy2017`. One can pass specific gene population to {func}`~scanpy.pp.calculate_qc_metrics` in order to calculate proportions of counts for these populations. Mitochondrial, ribosomal and hemoglobin genes are defined by distinct prefixes as listed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75df4b20-29ca-4e12-a878-94698a1b67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mitochondrial genes, \"MT-\" for human, \"Mt-\" for mouse\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(\"MT-\")\n",
    "# ribosomal genes\n",
    "adata.var[\"ribo\"] = adata.var_names.str.startswith((\"RPS\", \"RPL\"))\n",
    "# hemoglobin genes\n",
    "adata.var[\"hb\"] = adata.var_names.str.contains(\"^HB[^(P)]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd36ca1-75c7-4716-8766-a5571951537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, qc_vars=[\"mt\", \"ribo\", \"hb\"], inplace=True, log1p=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525671d-cfd3-4989-ad06-91c6edfa3af8",
   "metadata": {},
   "source": [
    "One can now inspect violin plots of some of the computed QC metrics:\n",
    "\n",
    "* the number of genes expressed in the count matrix\n",
    "* the total counts per cell\n",
    "* the percentage of counts in mitochondrial genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9db90e7-57d8-4f78-b1f9-ffc3698df091",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e3e58-a05a-4fd1-ab77-f3b14232dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.violin(\n",
    "    adata,\n",
    "    [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"],\n",
    "    jitter=0.4,\n",
    "    multi_panel=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38975f8-b71f-435d-80e6-fbf5ce081091",
   "metadata": {},
   "source": [
    "With HoloViz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599ee82-ed50-4adc-b39a-f88e7b3c8bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "violins = []\n",
    "for i in [\"obs.n_genes_by_counts\", \"obs.total_counts\", \"obs.pct_counts_mt\"]:\n",
    "    violins.append(\n",
    "        hv.Violin(adata, vdims=i).opts(\n",
    "            ylabel='Value',\n",
    "            title=i.split('.')[-1],\n",
    "            show_grid=True,\n",
    "            ylim=(0,None),\n",
    "        )\n",
    "    )\n",
    "hv.Layout(violins).opts(axiswise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78eec5-6b08-4d4f-9c54-a3688984b899",
   "metadata": {},
   "source": [
    "Additionally, it is useful to consider QC metrics jointly by inspecting a scatter plot colored by `pct_counts_mt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddfd195-10cd-419d-b984-39bc29dfe56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.scatter(adata, \"total_counts\", \"n_genes_by_counts\", color=\"pct_counts_mt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c01481-b221-4cfa-9c1c-7ab6c17d610e",
   "metadata": {},
   "source": [
    "With HoloViz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff58af-3f55-4646-8307-7975b18b9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = (hv.Scatter(adata, \"obs.total_counts\", [\"obs.n_genes_by_counts\", \"obs.pct_counts_mt\"])\n",
    "    .opts(cmap=\"Viridis\",\n",
    "          color=\"obs.pct_counts_mt\",\n",
    "          colorbar=True,\n",
    "          width=400,\n",
    "          tools=['hover'],\n",
    "          show_grid=True,\n",
    "          title='pct_counts_mt',\n",
    "))\n",
    "scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6f565-7a2a-4ff5-a783-9dab32a007a2",
   "metadata": {},
   "source": [
    "Based on the QC metric plots, one could now remove cells that have too many mitochondrial genes expressed or too many total counts by setting manual or automatic thresholds. However, sometimes what appears to be poor QC metrics can be driven by real biology so we suggest starting with a very permissive filtering strategy and revisiting it at a later point. We therefore now only filter cells with less than 100 genes expressed and genes that are detected in less than 3 cells. \n",
    "\n",
    "Additionally, it is important to note that for datasets with multiple batches, quality control should be performed for each sample individually as quality control thresholds can very substantially between batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61508aa7-31f1-403c-96c2-09460427bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(adata, min_genes=100)\n",
    "sc.pp.filter_genes(adata, min_cells=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71c53c35-7f0d-4c8d-90cc-fdc7687e828d",
   "metadata": {},
   "source": [
    "### Doublet detection\n",
    "\n",
    "As a next step, we run a doublet detection algorithm. Identifying doublets is crucial as they can lead to misclassifications or distortions in downstream analysis steps. Scanpy contains the doublet detection method Scrublet {cite}`Wolock2019`. Scrublet predicts cell doublets using a nearest-neighbor classifier of observed transcriptomes and simulated doublets. {func}`scanpy.pp.scrublet` adds `doublet_score` and `predicted_doublet` to `.obs`. One can now either filter directly on `predicted_doublet` or use the `doublet_score` later during clustering to filter clusters with high doublet scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc52329-32e3-4c04-a5a6-be4184391219",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sc.pp.scrublet(adata, batch_key=\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bcdb2e",
   "metadata": {},
   "source": [
    "We can remove doublets by either filtering out the cells called as doublets, or waiting until we've done a clustering pass and filtering out any clusters with high doublet scores."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eca84d9a-1da7-40c5-ab50-a6bbc5cd6955",
   "metadata": {},
   "source": [
    ":::{seealso}\n",
    "Alternative methods for doublet detection within the scverse ecosystem are [DoubletDetection](https://github.com/JonathanShor/DoubletDetection) and [SOLO](https://docs.scvi-tools.org/en/stable/user_guide/models/solo.html). You can read more about these in the [Doublet Detection chapter](https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#doublet-detection) of Single Cell Best Practices.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae375a-5f9d-4ff6-a7b2-52d13d202fa8",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "The next preprocessing step is normalization. A common approach is count depth scaling with subsequent log plus one (log1p) transformation. Count depth scaling normalizes the data to a “size factor” such as the median count depth in the dataset, ten thousand (CP10k) or one million (CPM, counts per million). The size factor for count depth scaling can be controlled via `target_sum` in `pp.normalize_total`. We are applying median count depth normalization with log1p transformation (AKA log1PF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe44a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving count data\n",
    "adata.layers[\"counts\"] = adata.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053aed6d-f793-442d-afa8-46def6054b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing to median total counts\n",
    "sc.pp.normalize_total(adata)\n",
    "# Logarithmize the data\n",
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f634d44-4e23-4e0f-96c0-443b3a5ffda9",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "As a next step, we want to reduce the dimensionality of the dataset and only include the most informative genes. This step is commonly known as feature selection. The scanpy function `pp.highly_variable_genes` annotates highly variable genes by reproducing the implementations of Seurat {cite}`Satija2015`, Cell Ranger {cite}`Zheng2017`, and Seurat v3 {cite}`Stuart2019` depending on the chosen `flavor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241df3f-a23b-4f06-8c4e-a2de39200f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000, batch_key=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654984e9-e511-4e32-b025-054d41a1aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092a4526-d821-451a-9dea-1e717591a06d",
   "metadata": {},
   "source": [
    "TODO: with HoloViz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e42e0-f511-4280-af18-ba6b5af0495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['highly_variable']\n",
    "adata.var['means']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4e74b2-c177-47d1-b659-041e8b796231",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "Reduce the dimensionality of the data by running principal component analysis (PCA), which reveals the main axes of variation and denoises the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d36d8-3238-47a5-8950-049fd0473205",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb54e365-3989-432e-bce0-b0a8e46ac08c",
   "metadata": {},
   "source": [
    "Let us inspect the contribution of single PCs to the total variance in the data. This gives us information about how many PCs we should consider in order to compute the neighborhood relations of cells, e.g. used in the clustering function {func}`~scanpy.tl.leiden` or {func}`~scanpy.tl.tsne`. In our experience, there does not seem to be signifigant downside to overestimating the numer of principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f1a27-6c1b-4160-b28e-e172bb325d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(adata, n_pcs=50, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8730a4e2-a380-4649-a98c-f760bac5f4e0",
   "metadata": {},
   "source": [
    "with HoloViz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446e660-5006-4ba6-a22e-49aea8375bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = adata.uns['pca']['variance_ratio']\n",
    "\n",
    "x_positions = np.arange(1, len(arr) + 1)\n",
    "labels = ['PC{}'.format(i) for i in range(1, len(arr) + 1)]\n",
    "\n",
    "points = hv.Points((x_positions, arr), ['Ranking', 'Variance Ratio']).opts(color='Variance Ratio', cmap='magma_r', size=6, tools=['hover'])\n",
    "label_overlay = hv.Labels((x_positions, arr, labels), ['x', 'y'], 'text').opts(\n",
    "    text_font_size='8pt', text_align='left', yoffset=.003, angle=90, text_color='black')\n",
    "\n",
    "var_ratio_plot = (points * label_overlay).opts(\n",
    "    width=600, height=400, xlabel='Ranking', ylabel=None, title='Variance Ratio', show_grid=True)\n",
    "\n",
    "var_ratio_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa711f1f",
   "metadata": {},
   "source": [
    "You can also plot the principal components to see if there are any potentially undesired features (e.g. batch, QC metrics) driving signifigant variation in this dataset. In this case, there isn't anything too alarming, but it's a good idea to explore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f92649",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(\n",
    "    adata,\n",
    "    color=[\"sample\", \"sample\", \"pct_counts_mt\", \"pct_counts_mt\"],\n",
    "    dimensions=[(0, 1), (2, 3), (0, 1), (2, 3)],\n",
    "    ncols=2,\n",
    "    size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0284e4-da4a-4bac-8587-5cc3e3fce5ae",
   "metadata": {},
   "source": [
    "with HoloViz v1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22668482-112d-4bfc-a46a-0cc24295ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews.operation.datashader as hd\n",
    "import datashader as ds\n",
    "import colorcet as cc\n",
    "import panel as pn\n",
    "import numpy as np\n",
    "import holoviews as hv\n",
    "\n",
    "\n",
    "def create_hv_dr_plot(x_data, color_data, x_dim, y_dim, color_var, xaxis_label, yaxis_label, width=300, height=300, datashading=False):\n",
    "    \"\"\"\n",
    "    Helper function to create a single dimensionality reduction scatter plot with Holoviews and optional datashading.\n",
    "\n",
    "    Parameters:\n",
    "    - x_data: numpy.ndarray, dimensionality reduction data.\n",
    "    - color_data: numpy.ndarray, color values (categorical or continuous).\n",
    "    - x_dim, y_dim: int, indices for components.\n",
    "    - color_var: str, the name of the coloring variable.\n",
    "    - xaxis_label, yaxis_label: str, labels for the axes.\n",
    "    - width, height: int, dimensions of the plot.\n",
    "    - datashading: bool, whether to apply Datashader.\n",
    "\n",
    "    Returns:\n",
    "    - hv.Element: A configured HoloViews scatter plot or datashaded plot.\n",
    "    \"\"\"\n",
    "    # print(color_var, color_data.dtype.name)\n",
    "    cats = ['category', 'categorical', 'bool']\n",
    "    if color_data.dtype.name in cats:  # Categorical data\n",
    "        # print('categorical')\n",
    "        cmap = cc.b_glasbey_category10\n",
    "        show_legend = True\n",
    "        colorbar = False\n",
    "    else:  # Continuous data\n",
    "        # print('continuous')\n",
    "        cmap = 'Viridis_r'\n",
    "        show_legend = False\n",
    "        colorbar = True\n",
    "\n",
    "    # Create the base plot\n",
    "    plot = hv.Points(\n",
    "        (x_data[:, x_dim], x_data[:, y_dim], color_data),\n",
    "        [xaxis_label, yaxis_label], color_var\n",
    "    ).opts(\n",
    "        color=color_var,\n",
    "        cmap=cmap,\n",
    "        size=1,\n",
    "        alpha=0.5,\n",
    "        colorbar=colorbar,\n",
    "        padding=0,\n",
    "        tools=['hover'],\n",
    "        show_legend=show_legend,\n",
    "    )\n",
    "\n",
    "    if datashading:\n",
    "        if color_data.dtype.name in cats:\n",
    "            plot = hd.rasterize(plot, aggregator=ds.by(color_var, ds.count())).opts(cmap=cmap)\n",
    "            plot = hd.dynspread(plot, threshold=.5)\n",
    "            # Create a fake legend overlay for categorical case\n",
    "            unique_categories = np.unique(color_data)\n",
    "            color_key = dict(zip(unique_categories, (cmap[i % len(cmap)] for i in range(len(unique_categories)))))\n",
    "            legend_overlay = hv.NdOverlay({\n",
    "                str(cat): hv.Points([(0, 0)], label=str(cat)).opts(\n",
    "                    color=color_key[cat],\n",
    "                    size=0,\n",
    "                    legend_position='right',\n",
    "                    legend_cols = len(unique_categories) // 5,\n",
    "                )\n",
    "                for cat in unique_categories\n",
    "            })\n",
    "            plot = (plot * legend_overlay).opts(show_legend=True, legend_limit = len(unique_categories)+1) # legend still not displaying when more than a few\n",
    "            # print(unique_categories)\n",
    "        else:\n",
    "            plot = hd.rasterize(plot, aggregator=ds.mean(color_var)).opts(cmap=cmap, colorbar=colorbar)\n",
    "            plot = hd.dynspread(plot, threshold=.5)\n",
    "    return plot.opts(\n",
    "        title=f\"{color_var}\",\n",
    "        tools=['hover'],\n",
    "        show_legend=show_legend,\n",
    "        width=width,\n",
    "        height=height\n",
    "    )\n",
    "\n",
    "\n",
    "def hv_dr_plot_layout(adata, color, dimensions, dr_method=('X_pca', 'PCA')):\n",
    "    \"\"\"\n",
    "    Create a static layout of dimensionality reduction scatter plots.\n",
    "\n",
    "    Parameters:\n",
    "    - adata: AnnData object containing dimensionality reduction data in `.obsm` and metadata in `.obs`.\n",
    "    - color: list of str, coloring variables for each plot.\n",
    "    - dimensions: list of tuples, specifying component indices.\n",
    "    - dr_method: tuple, (key for the dimensionality reduction data in `.obsm`, label for the method).\n",
    "\n",
    "    Returns:\n",
    "    - hv.Layout: A layout of scatter plots.\n",
    "    \"\"\"\n",
    "    dr_key, dr_label = dr_method\n",
    "    plots = []\n",
    "    x_data = adata.obsm[dr_key]\n",
    "    for color_var, (x_dim, y_dim) in zip(color, dimensions):\n",
    "        color_data = adata.obs[color_var].values\n",
    "        plot = create_hv_dr_plot(\n",
    "            x_data, color_data, x_dim, y_dim, color_var,\n",
    "            f'{dr_label} {x_dim + 1}', f'{dr_label} {y_dim + 1}', width=350, height=300,\n",
    "            datashading=True,\n",
    "        )\n",
    "        plots.append(plot)\n",
    "\n",
    "    layout = hv.Layout(plots).opts(shared_axes=False, axiswise=True)\n",
    "    return layout\n",
    "\n",
    "\n",
    "layout = hv_dr_plot_layout(\n",
    "    adata=adata,\n",
    "    color=[\"sample\", \"sample\", \"pct_counts_mt\", \"pct_counts_mt\"],\n",
    "    dimensions=[(0, 1), (2, 3), (0, 1), (2, 3)],\n",
    "    dr_method=('X_pca', 'PCA')\n",
    ")\n",
    "layout.cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5058451b-446d-4ecf-8121-900fa7d3d612",
   "metadata": {},
   "source": [
    "with HoloViz v2 (UI for axes and coloring):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11a043-798a-4347-bc5f-92abcb31f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from panel.io import hold\n",
    "\n",
    "def create_dr_app(adata, datashade=True):\n",
    "    dr_options = {key: key.split('_')[1].upper() for key in adata.obsm.keys()}\n",
    "    initial_dr_key = list(dr_options.keys())[0]  # Use the first available reduction as default\n",
    "    x_data = adata.obsm[initial_dr_key]\n",
    "    num_dims = x_data.shape[1]\n",
    "    dim_options = [f\"{dr_options[initial_dr_key]} {i+1}\" for i in range(num_dims)]\n",
    "    color_options = list(adata.obs.columns)  # Use all columns from `.obs`\n",
    "\n",
    "    dr_select = pn.widgets.Select(name='Dimensionality Reduction', options=list(dr_options.keys()), value=initial_dr_key)\n",
    "    xaxis = pn.widgets.Select(name='X-axis', options=dim_options, value=dim_options[0])\n",
    "    yaxis = pn.widgets.Select(name='Y-axis', options=dim_options, value=dim_options[1])\n",
    "    color = pn.widgets.Select(name='Color', options=color_options, value=color_options[0])\n",
    "    datashading_switch = pn.widgets.Checkbox(name='Enable Datashader', value=datashade)\n",
    "\n",
    "    def update_plot(dr_select, xaxis, yaxis, color, datashading):\n",
    "        x_data = adata.obsm[dr_select]\n",
    "        x_dim = int(xaxis.split()[-1]) - 1\n",
    "        y_dim = int(yaxis.split()[-1]) - 1\n",
    "        color_data = adata.obs[color].values\n",
    "        dr_label = dr_options[dr_select]\n",
    "\n",
    "        return create_hv_dr_plot(\n",
    "            x_data, color_data, x_dim, y_dim, color,\n",
    "            xaxis, yaxis, width=550, height=500, datashading=datashading\n",
    "        )\n",
    "\n",
    "    # Update all axis options (simultaneously with @hold) when dimensionality reduction method changes\n",
    "    @hold()\n",
    "    def update_axis_options(event):\n",
    "        x_data = adata.obsm[event.new]\n",
    "        num_dims = x_data.shape[1]\n",
    "        dr_label = dr_options[event.new]\n",
    "        dim_options = [f\"{dr_label} {i+1}\" for i in range(num_dims)]\n",
    "        xaxis.options = dim_options\n",
    "        yaxis.options = dim_options\n",
    "        xaxis.value = dim_options[0]\n",
    "        yaxis.value = dim_options[1]\n",
    "\n",
    "    dr_select.param.watch(update_axis_options, 'value')\n",
    "\n",
    "    def enforce_different_axes(event):\n",
    "        if xaxis.value == yaxis.value:\n",
    "            available_options = [opt for opt in yaxis.options if opt != xaxis.value]\n",
    "            if available_options:\n",
    "                yaxis.value = available_options[0]\n",
    "\n",
    "    xaxis.param.watch(enforce_different_axes, 'value')\n",
    "    yaxis.param.watch(enforce_different_axes, 'value')\n",
    "\n",
    "    plot_pane = pn.bind(update_plot, dr_select=dr_select, xaxis=xaxis, yaxis=yaxis, color=color, datashading=datashading_switch)\n",
    "\n",
    "    app = pn.Row(pn.WidgetBox(dr_select, xaxis, yaxis, color, datashading_switch), plot_pane)\n",
    "    return app\n",
    "\n",
    "\n",
    "interactive_app = create_dr_app(adata, datashade=True)\n",
    "interactive_app.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27147fca-c120-468d-8a5c-6479ece27848",
   "metadata": {},
   "source": [
    "## Nearest neighbor graph constuction and visualization\n",
    "\n",
    "Let us compute the neighborhood graph of cells using the PCA representation of the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3adfa7-0be0-4232-88fa-e0540c5c3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f7719-e418-401a-b006-c1eb524d7a2e",
   "metadata": {},
   "source": [
    "This graph can then be embedded in two dimensions for visualiztion with UMAP (McInnes et al., 2018):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0151a0-ce62-40e6-ba1b-2f4505b6b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f818f-66c7-40c7-b834-47cf5f02a1fa",
   "metadata": {},
   "source": [
    "We can now visualize the UMAP according to the `sample`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aba38e-9c07-484b-a222-5f2ec108e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=\"sample\",\n",
    "    # Setting a smaller point size to prevent overlap\n",
    "    size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d336906-9a29-41cb-a8ef-3258e1d4e9bb",
   "metadata": {},
   "source": [
    "with HoloViz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573d42d-7a9d-4dd8-b53a-65779d209e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = hv_dr_plot_layout(\n",
    "    adata=adata,\n",
    "    color=[\"sample\", \"pct_counts_mt\"],\n",
    "    dimensions=[(0, 1), (0, 1)],\n",
    "    dr_method=('X_umap', 'UMAP')\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4193a-cc23-4bf2-8d90-dec26a958800",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_app.objects[0][0].value='X_umap'\n",
    "interactive_app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d472937-b5b8-4d38-88d5-2af4d0718f1e",
   "metadata": {},
   "source": [
    "Even though the data considered in this tutorial includes two different samples, we only observe a minor batch effect and we can continue with clustering and annotation of our data. \n",
    "\n",
    "If you inspect batch effects in your UMAP it can be beneficial to integrate across samples and perform batch correction/integration. We recommend checking out [`scanorama`](https://github.com/brianhie/scanorama) and [`scvi-tools`](https://scvi-tools.org) for batch integration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "358da4af-c7ed-4479-87a7-ecd9d9765e1a",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "As with Seurat and many other frameworks, we recommend the Leiden graph-clustering method (community detection based on optimizing modularity) {cite}`Traag2019`. Note that Leiden clustering directly clusters the neighborhood graph of cells, which we already computed in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb19be-3df1-4a17-ad84-16b50a9348ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Using the igraph implementation and a fixed number of iterations can be significantly faster, especially for larger datasets\n",
    "sc.tl.leiden(adata, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616f3f6-69f8-4c66-ac00-48d328dcf755",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=[\"leiden\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210bf47c-64be-4a37-a6ef-dc869c4db352",
   "metadata": {},
   "source": [
    "with HoloViz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ebdb7-16e9-46b4-a367-08989d6ed448",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = hv_dr_plot_layout(\n",
    "    adata=adata,\n",
    "    color=[\"sample\", \"leiden\"],\n",
    "    dimensions=[(0, 1), (0, 1)],\n",
    "    dr_method=('X_umap', 'UMAP')\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587a995-df5b-4f20-bfcd-5df259b3fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_w_leiden = create_dr_app(adata, datashade=True)\n",
    "app_w_leiden.objects[0][0].value='X_umap'\n",
    "app_w_leiden.objects[0][3].value='leiden'\n",
    "app_w_leiden.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7410a1-333a-4f21-b53e-91af768b07c7",
   "metadata": {},
   "source": [
    "## Re-assess quality control and cell filtering \n",
    "\n",
    "As indicated before, we will now re-assess our filtering strategy by visualizing different QC metrics using UMAP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1818fbe-0e7d-467f-bdd1-3b690c32ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"leiden\", \"predicted_doublet\", \"doublet_score\"],\n",
    "    # increase horizontal space between panels\n",
    "    wspace=0.5,\n",
    "    size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14802ae-cd83-4ddb-9afc-0d59a91f5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0, 1)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c255f6-29b6-4c0a-bd52-d080bb4802be",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = hv_dr_plot_layout(\n",
    "    adata=adata,\n",
    "    color=[\"leiden\", \"predicted_doublet\", \"doublet_score\"],\n",
    "    dimensions=[(0, 1)] *3,\n",
    "    dr_method=('X_umap', 'UMAP')\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad2b94-ab9b-48a3-aa0c-551203d3cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"leiden\", \"log1p_total_counts\", \"pct_counts_mt\", \"log1p_n_genes_by_counts\"],\n",
    "    wspace=0.5,\n",
    "    ncols=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f2ceea-81d3-406e-bc76-45baf05c4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = hv_dr_plot_layout(\n",
    "    adata=adata,\n",
    "    color=[\"leiden\", \"log1p_total_counts\", \"pct_counts_mt\", \"log1p_n_genes_by_counts\"],\n",
    "    dimensions=[(0, 1)]*4,\n",
    "    dr_method=('X_umap', 'UMAP')\n",
    ")\n",
    "layout.cols(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece397a-e473-4633-b552-a7e430095c10",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manual cell-type annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e54a09",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "This section of the tutorial is expanded upon using prior knowledge resources like automated assignment and gene enrichment in the scverse tutorial [here](https://scverse-tutorials.readthedocs.io/en/latest/notebooks/basic-scrna-tutorial.html#cell-type-annotation)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff5d831",
   "metadata": {},
   "source": [
    "Cell type annotation is laborous and repetitive task, one which typically requires multiple rounds of subclustering and re-annotation. It's difficult to show the entirety of the process in this tutorial, but we aim to show how the tools scanpy provides assist in this process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc966c08-e87e-499a-9a9e-db40b243deb9",
   "metadata": {},
   "source": [
    "We have now reached a point where we have obtained a set of cells with decent quality, and we can proceed to their annotation to known cell types. Typically, this is done using genes that are exclusively expressed by a given cell type, or in other words these genes are the marker genes of the cell types, and are thus used to distinguish the heterogeneous groups of cells in our data. Previous efforts have collected and curated various marker genes into available resources, such as [CellMarker](http://bio-bigdata.hrbmu.edu.cn/CellMarker/), [TF-Marker](http://bio.liclab.net/TF-Marker/), and [PanglaoDB](https://panglaodb.se/). The [cellxgene gene expression tool](https://cellxgene.cziscience.com/gene-expression) can also be quite useful to see which cell types a gene has been expressed in across many existing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bc8b4d-dd05-41c2-befd-048a5eea6afd",
   "metadata": {},
   "source": [
    "Commonly and classically, cell type annotation uses those marker genes subsequent to the grouping of the cells into clusters. So, let's generate a set of clustering solutions which we can then use to annotate our cell types. Here, we will use the Leiden clustering algorithm which will extract cell communities from our nearest neighbours graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a1050-a073-4d82-b568-3cb943f9fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in [0.02, 0.5, 2.0]:\n",
    "    sc.tl.leiden(\n",
    "        adata, key_added=f\"leiden_res_{res:4.2f}\", resolution=res, flavor=\"igraph\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbffb2d3-e8fe-4bfb-aa8a-8d490254dcb1",
   "metadata": {},
   "source": [
    "Notably, the number of clusters that we define is largely arbitrary, and so is the `resolution` parameter that we use to control for it. As such, the number of clusters is ultimately bound to the stable and biologically-meaningful groups that we can ultimately distringuish, typically done by experts in the corresponding field or by using expert-curated prior knowledge in the form of markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1275cb4-9f1e-4f37-8c90-eb5d0abd679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"leiden_res_0.02\", \"leiden_res_0.50\", \"leiden_res_2.00\"],\n",
    "    legend_loc=\"on data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[\"leiden_res_0.02\", \"leiden_res_0.50\", \"leiden_res_2.00\"],\n",
    "    legend_loc=\"on data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ca6a0e-c46c-4b7d-859f-e9c971f05d5a",
   "metadata": {},
   "source": [
    "Though UMAPs should not be over-interpreted, here we can already see that in the highest resolution our data is over-clustered, while the lowest resolution is likely grouping cells which belong to distinct cell identities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cac979-c45d-4639-ac0a-18f85aa383e1",
   "metadata": {},
   "source": [
    "### Marker gene set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc891a7-e0e8-45e8-97d9-46eb74f55cde",
   "metadata": {},
   "source": [
    "Let's define a set of marker genes for the main cell types that we expect to see in this dataset. These were adapted from [Single Cell Best Practices annotation chapter](https://www.sc-best-practices.org/cellular_structure/annotation.html), for a more detailed overview and best practices in cell type annotation, we refer the user to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b1f83e-c4e2-48e4-954f-72abac5b5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes = {\n",
    "    \"CD14+ Mono\": [\"FCN1\", \"CD14\"],\n",
    "    \"CD16+ Mono\": [\"TCF7L2\", \"FCGR3A\", \"LYN\"],\n",
    "    # Note: DMXL2 should be negative\n",
    "    \"cDC2\": [\"CST3\", \"COTL1\", \"LYZ\", \"DMXL2\", \"CLEC10A\", \"FCER1A\"],\n",
    "    \"Erythroblast\": [\"MKI67\", \"HBA1\", \"HBB\"],\n",
    "    # Note HBM and GYPA are negative markers\n",
    "    \"Proerythroblast\": [\"CDK6\", \"SYNGR1\", \"HBM\", \"GYPA\"],\n",
    "    \"NK\": [\"GNLY\", \"NKG7\", \"CD247\", \"FCER1G\", \"TYROBP\", \"KLRG1\", \"FCGR3A\"],\n",
    "    \"ILC\": [\"ID2\", \"PLCG2\", \"GNLY\", \"SYNE1\"],\n",
    "    \"Naive CD20+ B\": [\"MS4A1\", \"IL4R\", \"IGHD\", \"FCRL1\", \"IGHM\"],\n",
    "    # Note IGHD and IGHM are negative markers\n",
    "    \"B cells\": [\n",
    "        \"MS4A1\",\n",
    "        \"ITGB1\",\n",
    "        \"COL4A4\",\n",
    "        \"PRDM1\",\n",
    "        \"IRF4\",\n",
    "        \"PAX5\",\n",
    "        \"BCL11A\",\n",
    "        \"BLK\",\n",
    "        \"IGHD\",\n",
    "        \"IGHM\",\n",
    "    ],\n",
    "    \"Plasma cells\": [\"MZB1\", \"HSP90B1\", \"FNDC3B\", \"PRDM1\", \"IGKC\", \"JCHAIN\"],\n",
    "    # Note PAX5 is a negative marker\n",
    "    \"Plasmablast\": [\"XBP1\", \"PRDM1\", \"PAX5\"],\n",
    "    \"CD4+ T\": [\"CD4\", \"IL7R\", \"TRBC2\"],\n",
    "    \"CD8+ T\": [\"CD8A\", \"CD8B\", \"GZMK\", \"GZMA\", \"CCL5\", \"GZMB\", \"GZMH\", \"GZMA\"],\n",
    "    \"T naive\": [\"LEF1\", \"CCR7\", \"TCF7\"],\n",
    "    \"pDC\": [\"GZMB\", \"IL3RA\", \"COBLL1\", \"TCF4\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96995645-6024-4663-ad45-79e7e3aaea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, marker_genes, groupby=\"leiden_res_0.02\", standard_scale=\"var\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90fcd55",
   "metadata": {},
   "source": [
    "There are fairly clear patterns of expression for our markers show here, which we can use to label our coarsest clustering with broad lineages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"cell_type_lvl1\"] = adata.obs[\"leiden_res_0.02\"].map(\n",
    "    {\n",
    "        \"0\": \"Lymphocytes\",\n",
    "        \"1\": \"Monocytes\",\n",
    "        \"2\": \"Erythroid\",\n",
    "        \"3\": \"B Cells\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49acdff-5606-4979-b08f-e6e314b782a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.dotplot(adata, marker_genes, groupby=\"leiden_res_0.50\", standard_scale=\"var\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b34f4-2c5f-48ba-8b59-d0838ac1bfa3",
   "metadata": {},
   "source": [
    "This seems like a resolution that suitable to distinguish most of the different cell types in our data. As such, let's try to annotate those by manually using the dotplot above, together with the UMAP of our clusters. Ideally, one would also look specifically into each cluster, and attempt to subcluster those if required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904fd57-ae61-4cfa-acae-82fc36631179",
   "metadata": {},
   "source": [
    "### Differentially-expressed Genes as Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578a42c-c43b-484e-8a82-3b9ed188b94c",
   "metadata": {},
   "source": [
    "Furthermore, one can also calculate marker genes per cluster and then look up whether we can link those marker genes to any known biology, such as cell types and/or states. This is typically done using simple statistical tests, such as Wilcoxon and t-test, for each cluster vs the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69a65c-199f-4883-9037-1df388b06861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain cluster-specific differentially expressed genes\n",
    "sc.tl.rank_genes_groups(adata, groupby=\"leiden_res_0.50\", method=\"wilcoxon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b74f5-dd51-457d-9715-b9a0ccbfff4a",
   "metadata": {},
   "source": [
    "We can then visualize the top 5 differentially-expressed genes on a dotplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf45dad-5f3d-465b-acd7-aa4f8bc42f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.rank_genes_groups_dotplot(\n",
    "    adata, groupby=\"leiden_res_0.50\", standard_scale=\"var\", n_genes=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b9e00",
   "metadata": {},
   "source": [
    "We can then use these genes to figure out what cell types we're looking at. For example, Cluster 7 is expressing [*NKG7*](https://www.genecards.org/cgi-bin/carddisp.pl?gene=NKG7&keywords=nkg7) and [*GNLY*](https://www.genecards.org/cgi-bin/carddisp.pl?gene=GNLY&keywords=GNLY), suggesting these are [NK cells](https://en.wikipedia.org/wiki/Natural_killer_cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd5c7fc",
   "metadata": {},
   "source": [
    "To create your own plots, or use a more automated approach, the differentially expressed genes can be extracted in a convenient format with {func}`scanpy.get.rank_genes_groups_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf24a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.get.rank_genes_groups_df(adata, group=\"7\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef390e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_cluster_genes = sc.get.rank_genes_groups_df(adata, group=\"7\").head(5)[\"names\"]\n",
    "sc.pl.umap(\n",
    "    adata,\n",
    "    color=[*dc_cluster_genes, \"leiden_res_0.50\"],\n",
    "    legend_loc=\"on data\",\n",
    "    frameon=False,\n",
    "    ncols=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789cdf32",
   "metadata": {},
   "source": [
    "You may have noticed that the p-values found here are extremely low. This is due to the statistical test being performed considering each cell as an independent sample. For a more conservative approach you may want to consider \"pseudo-bulking\" your data by sample (*e.g.* `sc.get.aggregate(adata, by=[\"sample\", \"cell_type\"], func=\"sum\", layer=\"counts\")`) and using a more powerful differential expression tool, like [`pydeseq2`](https://pydeseq2.readthedocs.io/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439e7509-d165-4a32-b563-9cde4084e849",
   "metadata": {},
   "source": [
    "# HoloViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d6893-befc-4a8e-b295-467a4fdda0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata.write(filename='adata.h5ad')\n",
    "adata = ad.read_h5ad('adata.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c79bb-a6b4-4715-b946-d13b72061f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d303d8-975f-4b9e-9204-729341c66f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc1658-8ef3-4299-9541-36d73be94321",
   "metadata": {},
   "source": [
    "adata \n",
    "- X : main data as n_obs × n_vars array = 17041 × 23427\n",
    "- obs (observation/cell vectors as pandas Series): 'sample', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_ribo', 'log1p_total_counts_ribo', 'pct_counts_ribo', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'n_genes', 'doublet_score', 'predicted_doublet', 'leiden', 'leiden_res_0.02', 'leiden_res_0.50', 'leiden_res_2.00', 'cell_type_lvl1'\n",
    "- var (variable/gene vectors as pandas Series): 'mt', 'ribo', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'\n",
    "- uns (unstructured meta, config, stats as dicts): 'scrublet', 'log1p', 'hvg', 'pca', 'sample_colors', 'neighbors', 'umap', 'leiden', 'leiden_colors', 'predicted_doublet_colors', 'leiden_res_0.02', 'leiden_res_0.50', 'leiden_res_2.00', 'leiden_res_0.02_colors', 'leiden_res_0.50_colors', 'leiden_res_2.00_colors', 'rank_genes_groups', 'dendrogram_leiden_res_0.50'\n",
    "- obsm (observation/cell matrices as n_obs x whatever array): 'X_pca', 'X_umap'\n",
    "- varm (variable/gene matrices as n_var x whatever array): 'PCs'\n",
    "- layers (array transforms, same size as main data): 'counts'\n",
    "- obsp (paired observation/cell annotations as n_obs x n_obs array): 'distances', 'connectivities'\n",
    "- var_names (variable/gene vectors as pandas Index): names of genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0969d3f-951d-4a83-8f7a-fff3f30acac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['leiden_res_0.50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be24e47-30e7-4f33-9399-e836e999751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from holoviews.operation.datashader import datashade, rasterize\n",
    "hv.extension('bokeh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa39c2f-6ba6-4de5-899c-af98a42eeb99",
   "metadata": {},
   "source": [
    "### Convert adata to xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2e8b2-1ad0-40a9-8228-5f0c9047ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b553e0-91f3-4f87-82b2-3ce651eaedc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3ca7c-c7ba-4a14-a901-9d99a8ede53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_X = sparse.COO.from_scipy_sparse(adata.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ef7bb-6d43-4244-b96f-dd634fa48c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the sparse matrix to a dense array\n",
    "# dense_data = adata.X.toarray()\n",
    "\n",
    "# Step 1: Convert primary data (X) to an xarray DataArray\n",
    "data_array = xr.DataArray(\n",
    "    sparse_X,\n",
    "    dims=[\"cells\", \"genes\"],\n",
    "    coords={\n",
    "        \"cells\": adata.obs_names,\n",
    "        \"genes\": adata.var_names,\n",
    "        \"cell_type_lvl1\": (\"cells\", adata.obs[\"cell_type_lvl1\"]),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea640cc5-0242-44ef-85c6-c5b14a37fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Add PCA and UMAP embeddings to the xarray dataset\n",
    "embeddings = xr.Dataset(\n",
    "    {\n",
    "        \"X_pca\": ((\"cells\", \"pca_components\"), adata.obsm[\"X_pca\"]),\n",
    "        \"X_umap\": ((\"cells\", \"umap_components\"), adata.obsm[\"X_umap\"]),\n",
    "    },\n",
    "    coords={\"cells\": adata.obs_names}\n",
    ")\n",
    "\n",
    "# Combine `data_array` and `embeddings` into one xarray Dataset\n",
    "xr_dataset = xr.Dataset({\"data\": data_array}, coords=data_array.coords)\n",
    "xr_dataset = xr_dataset.merge(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cec1c9c-349b-4c79-a076-863db44e8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee75f902-aa38-4c37-b0c5-6cc50335b443",
   "metadata": {},
   "source": [
    "### Alt, Convert the obs and var to pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925d2346-546a-4904-91a1-638296c32136",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm['X_umap'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a3d96-0ba4-4c66-9084-55e3e70608f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_df = pd.DataFrame(adata.obsm['X_umap'], columns=['UMAP1', 'UMAP2'])\n",
    "pca_df = pd.DataFrame(adata.obsm['X_pca'], columns=[f'PCA{1+i}' for i in range(adata.obsm['X_pca'].shape[-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639b5f4-53bc-4d11-b54e-2fffd97943ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df = adata.obs.join(umap_df.set_index(adata.obs.index))\n",
    "obs_df =  obs_df.join(pca_df.set_index(adata.obs.index))\n",
    "var_df = adata.var.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838ba0cc-9a6e-468b-905a-51f2136bb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract expression data for marker genes\n",
    "sel_genes = marker_genes['CD16+ Mono'] #[\"TCF7L2\", \"FCGR3A\", \"LYN\"],\n",
    "expression_df = pd.DataFrame(\n",
    "    adata[:, sel_genes].X.toarray(), \n",
    "    columns=sel_genes, \n",
    "    index=adata.obs_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd58c1aa-7866-458c-aea9-41d4223344bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# later try to datshade jittered scatter as overlay using .opts(jitter=)\n",
    "cols2plot = [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\"]\n",
    "violins = []\n",
    "for col in cols2plot:\n",
    "    violins.append(obs_df[col].hvplot.violin(width=300, ylabel='Value', title=col))\n",
    "hv.Layout(violins).opts(shared_axes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54cc148-7c59-4315-876e-303ef3679331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FR.. hide hover tool over non-data/empty pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8a60b-3cbd-42ca-8e0a-a36100524a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df.hvplot.scatter(x=\"total_counts\", y=\"n_genes_by_counts\", color=\"pct_counts_mt\", cmap='Viridis', rasterize=True, title='pct_counts_mt', aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a23f26-a235-41ba-a9a6-699e65b8c23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bug.. cannot get legend while using rasterize or datashade\n",
    "# bug.. cannot set color_key while using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817d02c-ada2-4013-a9b6-fa3f2e828b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca1_2_count = obs_df.hvplot.scatter(x=\"PCA1\", y=\"PCA2\", color=\"pct_counts_mt\", cmap='Viridis', title='pct_counts_mt', rasterize=True, cnorm='eq_hist', aspect=1)\n",
    "pca1_2_samp = obs_df.hvplot.scatter(x=\"PCA1\", y=\"PCA2\", by=\"sample\", legend=True, color=['blue', 'orange'], title='sample', datashade=True, cnorm='eq_hist', aspect=1)\n",
    "# color_key={'s1d1':'blue', 's1d3':'orange'},\n",
    "pca1_2_samp + pca1_2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42813cdf-ac02-4861-85d9-a160c1ac32d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap1_2_count = obs_df.hvplot.scatter(x=\"UMAP1\", y=\"UMAP2\", color=\"pct_counts_mt\", cmap='Viridis', title='pct_counts_mt', rasterize=True, cnorm='eq_hist', aspect=1)\n",
    "umap1_2_samp = obs_df.hvplot.scatter(x=\"UMAP1\", y=\"UMAP2\", by=\"sample\", legend=True, color=['blue', 'orange'], title='sample', datashade=True, cnorm='eq_hist', aspect=1)\n",
    "umap1_2_samp + umap1_2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f22f3d-35f0-4fdd-a64c-e050f979310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datashader as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55ef3a-8fdf-49ff-a5bd-21861416037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = hv.Points(obs_df, kdims=['UMAP1', 'UMAP2'], vdims=['leiden_res_0.50'])\n",
    "umap1_2_lieden_hv = rasterize(points, aggregator=ds.by('leiden_res_0.50')).opts(\n",
    "        cmap='Category20', frame_height=300, aspect=1, tools=['hover'], title='leiden, HoloViews')\n",
    "\n",
    "umap1_2_lieden_hvplot = obs_df.hvplot.scatter(x=\"UMAP1\", y=\"UMAP2\", by=\"leiden_res_0.50\", cmap='Category20', title='leiden, hvPlot', datashade=True, cnorm='eq_hist', aspect=1)\n",
    "umap1_2_lieden_hv + umap1_2_lieden_hvplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd9e20-dbf3-43a6-bbc1-4821fb7354c0",
   "metadata": {},
   "source": [
    "### generic dotplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c521e20-a005-470a-a598-2e6277340f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'gene': ['GeneA', 'GeneA', 'GeneB', 'GeneB', 'GeneC', 'GeneC'],\n",
    "    'cluster': ['Cluster1', 'Cluster2', 'Cluster1', 'Cluster2', 'Cluster1', 'Cluster2'],\n",
    "    'percentage': [80, 60, 90, 50, 70, 40],  # Percentage of cells (1-100)\n",
    "    'expression': [0.8, 0.3, 0.6, 0.2, 0.9, 0.4]  # Expression level (0-1)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Map percentage to point sizes ensuring max size doesn't overlap neighboring points\n",
    "# Define maximum point size (in pixels)\n",
    "max_point_size = 40\n",
    "df['size'] = (df['percentage'] / 100) * max_point_size\n",
    "\n",
    "# Create the scatter plot\n",
    "scatter = hv.Scatter(df, kdims=['gene', 'cluster'], vdims=['expression', 'size'])\n",
    "\n",
    "# Customize plot\n",
    "scatter = scatter.opts(\n",
    "    opts.Scatter(\n",
    "        xrotation=45,  # Rotate x-axis labels if necessary\n",
    "        color='expression',\n",
    "        cmap='Viridis',  # Choose a colormap\n",
    "        size='size',\n",
    "        line_color='black',  # Outline color of the points\n",
    "        marker='o',\n",
    "        tools=['hover'],  # Add hover tooltips\n",
    "        colorbar=True,\n",
    "        width=600,\n",
    "        height=400,\n",
    "        xlabel='gene',\n",
    "        ylabel='cluster',\n",
    "        show_legend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "hv.output(scatter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83faeadb-fe8f-40cc-91ee-50308e7f8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639eb332-acca-45a9-81ad-94190381a178",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefb2473-78fe-4493-8aac-0774a020f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_df[\"leiden_res_0.50\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa2a33-42fe-47c6-a9e7-cb557322c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def compute_dotplot_data(expression, groupby, gene_names, markers, expression_cutoff):\n",
    "    \"\"\"\n",
    "    Compute data required for creating a dot plot.\n",
    "\n",
    "    Parameters:\n",
    "    - expression: n_cells x n_genes matrix (could be sparse)\n",
    "    - groupby: array of cluster assignments, length n_cells\n",
    "    - gene_names: list of gene names, length n_genes\n",
    "    - markers: list of gene names to include in the dot plot\n",
    "    - expression_cutoff: value used to binarize expression (expression > cutoff)\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression']\n",
    "    \"\"\"\n",
    "    # Ensure expression is CSR format for efficient operations\n",
    "    if not isinstance(expression, csr_matrix):\n",
    "        expression = csr_matrix(expression)\n",
    "\n",
    "    # Map gene names to indices\n",
    "    gene_name_to_idx = {gene: idx for idx, gene in enumerate(gene_names)}\n",
    "    \n",
    "    # Get indices of marker genes\n",
    "    marker_indices = [gene_name_to_idx[gene] for gene in markers if gene in gene_name_to_idx]\n",
    "\n",
    "    # Subset the expression matrix to marker genes\n",
    "    expression_subset = expression[:, marker_indices]\n",
    "    marker_gene_names = [gene_names[idx] for idx in marker_indices]\n",
    "\n",
    "    # Convert groupby to numpy array if it's not already\n",
    "    groupby = np.array(groupby)\n",
    "    clusters = np.unique(groupby)\n",
    "\n",
    "    # Check if all clusters are numeric\n",
    "    clusters_series = pd.Series(clusters)\n",
    "    clusters_numeric = pd.to_numeric(clusters_series, errors='coerce')\n",
    "\n",
    "    if clusters_numeric.isnull().any():\n",
    "        # Not all clusters are numeric\n",
    "        convert_cluster_to_numeric = False\n",
    "    else:\n",
    "        convert_cluster_to_numeric = True\n",
    "\n",
    "    # Initialize list to collect results\n",
    "    results = []\n",
    "\n",
    "    # Binarize the expression data using the expression_cutoff\n",
    "    expression_binarized = expression_subset.copy()\n",
    "    expression_binarized.data = (expression_binarized.data > expression_cutoff).astype(int)\n",
    "    \n",
    "    # For each cluster\n",
    "    for cluster in clusters:\n",
    "        # Get indices of cells in the current cluster\n",
    "        cluster_mask = groupby == cluster\n",
    "        cluster_cell_indices = np.where(cluster_mask)[0]\n",
    "        \n",
    "        # Number of cells in the cluster\n",
    "        n_cells_in_cluster = len(cluster_cell_indices)\n",
    "        \n",
    "        # Subset the expression data to cells in the cluster\n",
    "        X_cluster = expression_subset[cluster_cell_indices, :]\n",
    "        X_cluster_binarized = expression_binarized[cluster_cell_indices, :]\n",
    "        \n",
    "        # Compute the sum of binarized expression per gene (number of cells expressing the gene)\n",
    "        expressing_cells = X_cluster_binarized.sum(axis=0).A1  # Sum over cells\n",
    "        \n",
    "        # Compute percentage of cells expressing each gene\n",
    "        percentage = (expressing_cells / n_cells_in_cluster) * 100  # Percentage\n",
    "        \n",
    "        # Compute mean expression per gene over all cells in cluster\n",
    "        total_expression = X_cluster.sum(axis=0).A1  # Sum of expression values per gene\n",
    "        mean_expression = total_expression / n_cells_in_cluster  # Mean expression\n",
    "        \n",
    "        # Collect results into DataFrame\n",
    "        cluster_results = pd.DataFrame({\n",
    "            'gene': marker_gene_names,\n",
    "            'cluster': cluster,\n",
    "            'percentage': percentage,\n",
    "            'mean_expression': mean_expression\n",
    "        })\n",
    "        results.append(cluster_results)\n",
    "\n",
    "    # Concatenate results from all clusters\n",
    "    df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    # Convert 'cluster' column to numeric if all clusters are numeric\n",
    "    if convert_cluster_to_numeric:\n",
    "        df['cluster'] = pd.to_numeric(df['cluster'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2bccd-67dd-44a8-a7ae-a506d4e58ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ab448-7241-4f3d-b674-b37323fd52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_data = compute_dotplot_data(adata.X, adata.obs['leiden_res_0.50'], adata.var_names, [\"ID2\", \"PLCG2\", \"GNLY\", \"SYNE1\"], .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b520a0-4784-4452-bfb8-a2e32e809fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca34dc36-15f0-43e5-8527-bf468f1c60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3dfc1e-66c2-4ccb-ae18-86d73a380f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dotplot(df, max_point_size=40):\n",
    "    \"\"\"\n",
    "    Create a dot plot from the DataFrame output by compute_dotplot_data.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression']\n",
    "    \"\"\"\n",
    "\n",
    "    # Map percentage to point sizes\n",
    "    max_point_size = max_point_size  # Adjust based on your plot dimensions\n",
    "    df['size'] = (df['percentage'] / df['percentage'].max()) * max_point_size\n",
    "\n",
    "    # Normalize mean_expression for color mapping\n",
    "    df['mean_expression_normalized'] = df['mean_expression'] / df['mean_expression'].max()\n",
    "\n",
    "    # Create the points plot\n",
    "    points = hv.Points(df, kdims=['gene', 'cluster'], vdims=['mean_expression_normalized', 'size', 'percentage', 'mean_expression'])\n",
    "    heatmap = hv.HeatMap(df, kdims=['gene', 'cluster'], vdims=['mean_expression_normalized'])\n",
    "\n",
    "    # Extract sorted unique cluster values\n",
    "    cluster_values = sorted(df['cluster'].unique())\n",
    "\n",
    "    # Create yticks as a list of tuples (position, label)\n",
    "    yticks = [(cluster, str(cluster)) for cluster in cluster_values]\n",
    "\n",
    "    # Determine ylim to make Y-axis tight to data extents\n",
    "    # Since we have invert_yaxis=True, the ylim should be from higher to lower values\n",
    "    min_cluster = min(cluster_values)\n",
    "    max_cluster = max(cluster_values)\n",
    "    # Assuming clusters are integers and we want to center ticks, adjust by 0.5\n",
    "    ylim = (max_cluster + 0.5, min_cluster - 0.5)\n",
    "\n",
    "    # Customize the plot\n",
    "    points = points.opts(\n",
    "            xrotation=90,             # Rotate x-axis labels if necessary\n",
    "            color='mean_expression_normalized',\n",
    "            cmap='reds',           # Choose a colormap\n",
    "            size='size',\n",
    "            line_color='white',       # Outline color of the points\n",
    "            line_alpha=.1,\n",
    "            marker='o',\n",
    "            tools=['hover'],          # Add hover tooltips\n",
    "            colorbar=True,\n",
    "            min_height=400,\n",
    "            responsive=True,\n",
    "            xlabel='Gene',\n",
    "            ylabel='Cluster',\n",
    "            invert_yaxis=True,        # Optional: invert y-axis to match conventional heatmap orientation\n",
    "            show_legend=False,\n",
    "            yticks=yticks,\n",
    "    )\n",
    "\n",
    "    heatmap = heatmap.opts(cmap='greys', fill_alpha=.2, ylim=ylim)\n",
    "\n",
    "    return heatmap * points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148df87-e231-46da-a2c3-49b69e185c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dotplot(dp_data, max_point_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473cff57-9f9b-48cb-983b-7c2370a48773",
   "metadata": {},
   "source": [
    "### Try to add a gene group labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e0b39-3537-40c2-837f-385563902ecc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "def plot_dotplot(df, max_point_size=40):\n",
    "    \"\"\"\n",
    "    Create a dot plot from the DataFrame output by compute_dotplot_data.\n",
    "    If 'gene_group' is present in df, include an adjoined plot above the main plot to show gene groupings.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression']\n",
    "          If 'gene_group' is present, includes gene groupings.\n",
    "    - max_point_size: Maximum size for the dots representing 100% percentage.\n",
    "    \"\"\"\n",
    "\n",
    "    # Map percentage to point sizes\n",
    "    df['size'] = (df['percentage'] / df['percentage'].max()) * max_point_size\n",
    "\n",
    "    # Normalize mean_expression for color mapping\n",
    "    df['mean_expression_normalized'] = df['mean_expression'] / df['mean_expression'].max()\n",
    "\n",
    "    # Ensure 'gene' is a categorical variable with the correct order\n",
    "    genes_order = df['gene'].drop_duplicates().tolist()\n",
    "    df['gene'] = pd.Categorical(df['gene'], categories=genes_order, ordered=True)\n",
    "\n",
    "    # Create the points plot\n",
    "    points = hv.Points(\n",
    "        df,\n",
    "        kdims=['gene', 'cluster'],\n",
    "        vdims=['mean_expression_normalized', 'size', 'percentage', 'mean_expression']\n",
    "    )\n",
    "\n",
    "    heatmap = hv.HeatMap(\n",
    "        df,\n",
    "        kdims=['gene', 'cluster'],\n",
    "        vdims=['mean_expression_normalized']\n",
    "    )\n",
    "\n",
    "    # Extract sorted unique cluster values\n",
    "    cluster_values = sorted(df['cluster'].unique())\n",
    "\n",
    "    # Ensure cluster_values is not empty\n",
    "    if not cluster_values:\n",
    "        raise ValueError(\"No clusters found in the data.\")\n",
    "\n",
    "    # Create yticks as a list of tuples (position, label)\n",
    "    yticks = [(cluster, str(cluster)) for cluster in cluster_values]\n",
    "\n",
    "    # Determine ylim to make Y-axis tight to data extents\n",
    "    min_cluster = min(cluster_values)\n",
    "    max_cluster = max(cluster_values)\n",
    "    ylim = (max_cluster + 0.5, min_cluster - 0.5)\n",
    "\n",
    "    # Customize the points plot\n",
    "    points = points.opts(\n",
    "        xrotation=90,             # Rotate x-axis labels if necessary\n",
    "        color='mean_expression_normalized',\n",
    "        cmap='reds',              # Choose a colormap\n",
    "        size='size',\n",
    "        line_color='white',       # Outline color of the points\n",
    "        line_alpha=0.1,\n",
    "        marker='o',\n",
    "        tools=['hover'],          # Add hover tooltips\n",
    "        colorbar=True,\n",
    "        min_height=400,\n",
    "        responsive=True,\n",
    "        xlabel='Gene',\n",
    "        ylabel='Cluster',\n",
    "        invert_yaxis=True,        # Invert y-axis to match conventional heatmap orientation\n",
    "        show_legend=False,\n",
    "        yticks=yticks,\n",
    "        ylim=ylim,\n",
    "    )\n",
    "\n",
    "    heatmap = heatmap.opts(\n",
    "        cmap='greys', \n",
    "        fill_alpha=0.2, \n",
    "        ylim=ylim,\n",
    "        yticks=yticks,\n",
    "    )\n",
    "\n",
    "    # Check if 'gene_group' is in df\n",
    "    if 'gene_group' in df.columns:\n",
    "        # Create the adjoined plot for gene groups\n",
    "        gene_groups = df[['gene', 'gene_group']].drop_duplicates()\n",
    "        gene_groups = gene_groups.groupby('gene_group')['gene'].apply(list).reset_index()\n",
    "\n",
    "        # Prepare the annotations (rectangles and labels)\n",
    "        annotations = []\n",
    "        x_positions = {gene: pos for pos, gene in enumerate(genes_order)}\n",
    "        for _, row in gene_groups.iterrows():\n",
    "            group = row['gene_group']\n",
    "            genes_in_group = row['gene']\n",
    "            start_gene = genes_in_group[0]\n",
    "            end_gene = genes_in_group[-1]\n",
    "            start_pos = x_positions[start_gene] - 0.5\n",
    "            end_pos = x_positions[end_gene] + 0.5\n",
    "            # Create a rectangle spanning from start_gene to end_gene\n",
    "            rect = hv.Rectangles([(start_pos, 0, end_pos, 1)])\n",
    "            text = hv.Text((start_pos + end_pos) / 2, 0.5, group).opts(text_align='center')\n",
    "            annotations.append(rect.opts(fill_alpha=0, line_width=2, line_color='black') * text)\n",
    "\n",
    "        # Combine annotations\n",
    "        annotations = hv.Overlay(annotations).opts(\n",
    "            xaxis=None,\n",
    "            yaxis=None,\n",
    "            show_frame=False,\n",
    "            show_grid=False,\n",
    "            height=50,\n",
    "            ylim=(0, 1),\n",
    "            xlim=(-0.5, len(genes_order) - 0.5),\n",
    "            bgcolor='white',\n",
    "        )\n",
    "\n",
    "        # Layout the annotations above the main plot\n",
    "        layout = (annotations + (heatmap * points)).cols(1)\n",
    "        return layout\n",
    "\n",
    "    else:\n",
    "        # No gene groups, return the main plot\n",
    "        return heatmap * points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044754a2-c22c-49e9-82a2-8d7455be6408",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_data = compute_dotplot_data(adata.X, adata.obs['leiden_res_0.50'], adata.var_names, marker_genes, .1)\n",
    "plot_dotplot(dp_data, max_point_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b46cd-9303-4cae-bd87-156022549ed2",
   "metadata": {},
   "source": [
    "### try to make the annotations a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc2fc9-2292-4d16-8889-98d0073a0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "def plot_dotplot(df, max_point_size=40):\n",
    "    \"\"\"\n",
    "    Create a dot plot from the DataFrame output by compute_dotplot_data.\n",
    "    If 'gene_group' is present in df, include annotations as an additional heatmap\n",
    "    placed above the main dotplot, which has a row colored to encode the gene groups,\n",
    "    and text labels for the gene groups.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression']\n",
    "          If 'gene_group' is present, includes gene groupings.\n",
    "    - max_point_size: Maximum size for the dots representing 100% percentage.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Map percentage to point sizes\n",
    "    df['size'] = (df['percentage'] / df['percentage'].max()) * max_point_size\n",
    "\n",
    "    # Normalize mean_expression for color mapping\n",
    "    df['mean_expression_normalized'] = df['mean_expression'] / df['mean_expression'].max()\n",
    "\n",
    "    # Ensure 'gene' is a categorical variable with the correct order\n",
    "    genes_order = df['gene'].drop_duplicates().tolist()\n",
    "    df['gene'] = pd.Categorical(df['gene'], categories=genes_order, ordered=True)\n",
    "\n",
    "    # Ensure 'cluster' is a categorical variable with a consistent order\n",
    "    clusters_order = df['cluster'].drop_duplicates().tolist()\n",
    "    df['cluster'] = pd.Categorical(df['cluster'], categories=clusters_order, ordered=True)\n",
    "\n",
    "    # Create the main heatmap and points plot\n",
    "    points = hv.Points(\n",
    "        df,\n",
    "        kdims=['gene', 'cluster'],\n",
    "        vdims=['mean_expression_normalized', 'size', 'percentage', 'mean_expression']\n",
    "    )\n",
    "\n",
    "    heatmap = hv.HeatMap(\n",
    "        df,\n",
    "        kdims=['gene', 'cluster'],\n",
    "        vdims=['mean_expression_normalized']\n",
    "    )\n",
    "\n",
    "    # Create yticks as a list of tuples (position, label)\n",
    "    yticks = list(enumerate(clusters_order))\n",
    "\n",
    "    # Customize the points plot\n",
    "    points = points.opts(\n",
    "        xrotation=90,\n",
    "        color='mean_expression_normalized',\n",
    "        cmap='reds',\n",
    "        size='size',\n",
    "        line_color='white',\n",
    "        line_alpha=0.1,\n",
    "        marker='o',\n",
    "        tools=['hover'],\n",
    "        colorbar=True,\n",
    "        min_height=400,\n",
    "        responsive=True,\n",
    "        xlabel='Gene',\n",
    "        ylabel='Cluster',\n",
    "        invert_yaxis=True,\n",
    "        show_legend=False,\n",
    "        yticks=yticks,\n",
    "    )\n",
    "\n",
    "    # Customize the heatmap\n",
    "    heatmap = heatmap.opts(\n",
    "        cmap='greys',\n",
    "        fill_alpha=0.2,\n",
    "        invert_yaxis=False,\n",
    "        yticks=yticks,\n",
    "    )\n",
    "\n",
    "    if 'gene_group' in df.columns:\n",
    "        # Create a DataFrame for the annotations heatmap\n",
    "        gene_groups = df[['gene', 'gene_group']].drop_duplicates()\n",
    "        # Map gene groups to integer codes\n",
    "        gene_groups['group_code'] = gene_groups['gene_group'].factorize()[0]\n",
    "\n",
    "        # Create a DataFrame for the annotations heatmap\n",
    "        annotations_df = gene_groups[['gene', 'group_code']].copy()\n",
    "        annotations_df['Group'] = 'Group'  # Dummy variable for y-axis\n",
    "\n",
    "        # Ensure 'gene' and 'Group' are categorical with the correct order\n",
    "        annotations_df['gene'] = pd.Categorical(annotations_df['gene'], categories=genes_order, ordered=True)\n",
    "        annotations_df['Group'] = pd.Categorical(annotations_df['Group'], categories=['Group'], ordered=True)\n",
    "\n",
    "        # Create the annotations heatmap\n",
    "        annotations_heatmap = hv.HeatMap(\n",
    "            annotations_df,\n",
    "            kdims=['gene', 'Group'],\n",
    "            vdims=['group_code']\n",
    "        )\n",
    "\n",
    "        # Customize the annotations heatmap\n",
    "        annotations_heatmap = annotations_heatmap.opts(\n",
    "            colorbar=False,\n",
    "            xaxis=None,\n",
    "            yaxis=None,\n",
    "            invert_yaxis=True,\n",
    "            responsive=True,\n",
    "            cmap= ['black', 'grey']*10,\n",
    "            tools=['hover'],\n",
    "            toolbar=None,\n",
    "        )\n",
    "\n",
    "        # Create text labels for the gene groups\n",
    "        # Calculate the center position of each gene group\n",
    "        gene_group_positions = gene_groups.groupby('gene_group')['gene'].apply(list)\n",
    "        text_annotations = []\n",
    "        for group, genes_in_group in gene_group_positions.items():\n",
    "            # Calculate the center position of the group\n",
    "            x_positions = [genes_order.index(gene) for gene in genes_in_group]\n",
    "            x_center = (min(x_positions) + max(x_positions)) / 2\n",
    "            text = hv.Text(genes_order[int(x_center)], 'Group', group).opts(\n",
    "                text_align='right',\n",
    "                text_baseline='middle',\n",
    "                text_font_size='8pt',\n",
    "                text_color='black',\n",
    "                xaxis=None,\n",
    "                yaxis=None,\n",
    "                angle=90,\n",
    "            )\n",
    "            text_annotations.append(text)\n",
    "\n",
    "        # Combine the text annotations\n",
    "        text_overlay = hv.Overlay(text_annotations)\n",
    "\n",
    "        # Overlay the text on the annotations heatmap\n",
    "        annotations_plot = (annotations_heatmap * text_overlay).opts(\n",
    "            xaxis=None,\n",
    "            yaxis=None,\n",
    "            responsive=True,\n",
    "            height=50,\n",
    "            toolbar=None,\n",
    "            show_frame=False,\n",
    "            show_grid=False,\n",
    "        )\n",
    "\n",
    "        # Stack the annotations_plot above the main plot\n",
    "        layout = hv.Layout([annotations_plot, heatmap * points]).cols(1).opts(\n",
    "            opts.Layout(shared_axes=True)\n",
    "        )\n",
    "        return layout, annotations_df\n",
    "\n",
    "    else:\n",
    "        # No gene groups, proceed without annotations\n",
    "        return heatmap * points\n",
    "\n",
    "\n",
    "dp_data = compute_dotplot_data(adata.X, adata.obs['leiden_res_0.50'], adata.var_names, marker_genes, .1)\n",
    "layout, annotations_df = plot_dotplot(dp_data, max_point_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69435b83-816e-48c4-acf8-083f51b13af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a1db8-21e4-4089-b905-7602dfd9ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284d3442-dad2-4ecc-80e5-1ad2aa928d97",
   "metadata": {},
   "source": [
    "## Try to fix the gene grouping display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a89b512-90a5-467d-b49f-18031dcb19ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def compute_dotplot_data(expression, groupby, gene_names, markers, expression_cutoff):\n",
    "    \"\"\"\n",
    "    Compute data required for creating a dot plot, handling markers as a list or a dictionary,\n",
    "    and allowing for genes to appear in multiple groups.\n",
    "\n",
    "    Parameters:\n",
    "    - expression: n_cells x n_genes matrix (could be sparse)\n",
    "    - groupby: array of cluster assignments, length n_cells\n",
    "    - gene_names: list of gene names, length n_genes\n",
    "    - markers: either a list of gene names or a dictionary with keys as group labels and values as lists of gene names\n",
    "    - expression_cutoff: value used for binarizing expression (expression > cutoff)\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression', 'gene_group']\n",
    "    \"\"\"\n",
    "    # Ensure expression is CSR format for efficient operations\n",
    "    if not isinstance(expression, csr_matrix):\n",
    "        expression = csr_matrix(expression)\n",
    "\n",
    "    # Map gene names to indices\n",
    "    gene_name_to_idx = {gene: idx for idx, gene in enumerate(gene_names)}\n",
    "\n",
    "    # Initialize variables\n",
    "    gene_group_list = []\n",
    "\n",
    "    # Check if markers is a dictionary or a list\n",
    "    if isinstance(markers, dict):\n",
    "        # Markers is a dictionary with group labels\n",
    "        # Flatten markers dictionary to get list of (gene, group)\n",
    "        marker_genes = []\n",
    "        for group, genes in markers.items():\n",
    "            for gene in genes:\n",
    "                if gene in gene_name_to_idx:\n",
    "                    marker_genes.append((gene, group))\n",
    "\n",
    "        # Do not remove duplicates, keep genes as they appear\n",
    "        # Get the list of gene indices, allowing for duplicates\n",
    "        marker_indices = [gene_name_to_idx[gene] for gene, group in marker_genes]\n",
    "        marker_gene_names = [gene for gene, group in marker_genes]\n",
    "        gene_groups = [group for gene, group in marker_genes]\n",
    "\n",
    "    elif isinstance(markers, list):\n",
    "        # Markers is a list of gene names\n",
    "        marker_genes = [gene for gene in markers if gene in gene_name_to_idx]\n",
    "\n",
    "        # Remove duplicates while preserving order\n",
    "        marker_genes = list(dict.fromkeys(marker_genes))\n",
    "\n",
    "        # Get indices of marker genes\n",
    "        marker_indices = [gene_name_to_idx[gene] for gene in marker_genes]\n",
    "        marker_gene_names = marker_genes\n",
    "        gene_groups = [None] * len(marker_gene_names)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Markers must be a list or a dictionary.\")\n",
    "\n",
    "    # Convert groupby to numpy array if it's not already\n",
    "    groupby = np.array(groupby)\n",
    "    clusters = np.unique(groupby)\n",
    "\n",
    "    # Check if all clusters are numeric\n",
    "    clusters_series = pd.Series(clusters)\n",
    "    clusters_numeric = pd.to_numeric(clusters_series, errors='coerce')\n",
    "\n",
    "    if clusters_numeric.isnull().any():\n",
    "        convert_cluster_to_numeric = False\n",
    "    else:\n",
    "        convert_cluster_to_numeric = True\n",
    "\n",
    "    # Initialize list to collect results\n",
    "    results = []\n",
    "\n",
    "    # For each marker gene (could be duplicated)\n",
    "    for gene_idx, gene_name, gene_group in zip(marker_indices, marker_gene_names, gene_groups):\n",
    "        # Get the expression vector for this gene\n",
    "        gene_expression = expression[:, gene_idx]\n",
    "\n",
    "        # Binarize the expression data using the expression_cutoff\n",
    "        gene_expression_binarized = gene_expression.copy()\n",
    "        gene_expression_binarized.data = (gene_expression_binarized.data > expression_cutoff).astype(int)\n",
    "\n",
    "        # For each cluster\n",
    "        for cluster in clusters:\n",
    "            # Get indices of cells in the current cluster\n",
    "            cluster_mask = groupby == cluster\n",
    "            cluster_cell_indices = np.where(cluster_mask)[0]\n",
    "\n",
    "            # Number of cells in the cluster\n",
    "            n_cells_in_cluster = len(cluster_cell_indices)\n",
    "\n",
    "            # Subset the expression data to cells in the cluster\n",
    "            X_cluster = gene_expression[cluster_cell_indices]\n",
    "            X_cluster_binarized = gene_expression_binarized[cluster_cell_indices]\n",
    "\n",
    "            # Compute the sum of binarized expression (number of cells expressing the gene)\n",
    "            expressing_cells = X_cluster_binarized.sum()\n",
    "\n",
    "            # Compute percentage of cells expressing the gene\n",
    "            percentage = (expressing_cells / n_cells_in_cluster) * 100  # Percentage\n",
    "\n",
    "            # Compute mean expression per gene over all cells in cluster\n",
    "            total_expression = X_cluster.sum()\n",
    "            mean_expression = total_expression / n_cells_in_cluster  # Mean expression\n",
    "\n",
    "            # Collect results into DataFrames\n",
    "            cluster_results = pd.DataFrame({\n",
    "                'gene': [gene_name],\n",
    "                'cluster': [cluster],\n",
    "                'percentage': [percentage],\n",
    "                'mean_expression': [mean_expression],\n",
    "                'gene_group': [gene_group]\n",
    "            })\n",
    "            results.append(cluster_results)\n",
    "\n",
    "    # Concatenate results from all clusters and all genes\n",
    "    df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    # # Convert 'cluster' column to numeric if all clusters are numeric\n",
    "    if convert_cluster_to_numeric:\n",
    "        df['cluster'] = pd.to_numeric(df['cluster'])\n",
    "\n",
    "    return df\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "def plot_dotplot(df, max_point_size=40):\n",
    "    \"\"\"\n",
    "    Create a dot plot from the DataFrame output by compute_dotplot_data,\n",
    "    handling genes that appear multiple times due to being in multiple groups.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression', 'gene_group']\n",
    "    - max_point_size: Maximum size for the dots representing 100% percentage.\n",
    "\n",
    "    Returns:\n",
    "    - plot: Holoviews object representing the dot plot.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Create a unique identifier for each gene entry\n",
    "    df = df.copy()\n",
    "    df['gene_id'] = df.apply(\n",
    "        lambda row: f\"{row['gene']} ({row['gene_group']})\" if pd.notnull(row['gene_group']) else row['gene'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Map percentage to point sizes\n",
    "    df['size'] = (df['percentage'] / df['percentage'].max()) * max_point_size\n",
    "\n",
    "    # Normalize mean_expression for color mapping\n",
    "    df['mean_expression_normalized'] = df['mean_expression'] / df['mean_expression'].max()\n",
    "\n",
    "    # Ensure 'gene_id' is a categorical variable with the correct order\n",
    "    gene_ids_order = df['gene_id'].drop_duplicates().tolist()\n",
    "    df['gene_id'] = pd.Categorical(df['gene_id'], categories=gene_ids_order, ordered=True)\n",
    "\n",
    "    # # Ensure 'cluster' is a categorical variable with a consistent order\n",
    "    # clusters_order = df['cluster'].drop_duplicates().tolist()\n",
    "    # df['cluster'] = pd.Categorical(df['cluster'], categories=clusters_order, ordered=True)\n",
    "\n",
    "    # Extract sorted unique cluster values\n",
    "    cluster_values = sorted(df['cluster'].unique())\n",
    "\n",
    "    # Determine ylim to make Y-axis tight to data extents\n",
    "    # Since we have invert_yaxis=True, the ylim should be from higher to lower values\n",
    "    min_cluster = min(cluster_values)\n",
    "    max_cluster = max(cluster_values)\n",
    "    # Assuming clusters are integers and we want to center ticks, adjust by 0.5\n",
    "    ylim = (max_cluster + 0.5, min_cluster - 0.5)\n",
    "\n",
    "    # Create yticks as a list of tuples (position, label)\n",
    "    yticks = [(cluster, str(cluster)) for cluster in cluster_values]\n",
    "\n",
    "    # Create the main heatmap and points plot\n",
    "    points = hv.Points(\n",
    "        df,\n",
    "        kdims=['gene_id', 'cluster'],\n",
    "        vdims=['mean_expression_normalized', 'size', 'percentage', 'mean_expression', 'gene_group']\n",
    "    )\n",
    "\n",
    "    # heatmap = hv.HeatMap(\n",
    "    #     df,\n",
    "    #     kdims=['gene_id', 'cluster'],\n",
    "    #     vdims=['mean_expression_normalized']\n",
    "    # )\n",
    "\n",
    "    # Create yticks as a list of tuples (index, label)\n",
    "    # yticks = list(enumerate(clusters_order))\n",
    "\n",
    "    # Customize the points plot\n",
    "    points = points.opts(\n",
    "        xrotation=90,\n",
    "        color='mean_expression_normalized',\n",
    "        cmap='Reds',\n",
    "        size='size',\n",
    "        line_color='black',\n",
    "        line_alpha=0.1,\n",
    "        marker='o',\n",
    "        tools=['hover'],\n",
    "        colorbar=True,\n",
    "        min_height=400,\n",
    "        responsive=True,\n",
    "        xlabel='Gene',\n",
    "        ylabel='Cluster',\n",
    "        invert_yaxis=False,\n",
    "        show_legend=False,\n",
    "        yticks=yticks,\n",
    "        ylim=ylim,\n",
    "    )\n",
    "\n",
    "    # # Customize the heatmap\n",
    "    # heatmap = heatmap.opts(\n",
    "    #     cmap='Greys',\n",
    "    #     fill_alpha=0.2,\n",
    "    #     invert_yaxis=True,\n",
    "    #     yticks=yticks,\n",
    "    #     ylim=ylim,\n",
    "    # )\n",
    "\n",
    "    if 'gene_group' in df.columns:\n",
    "        # Create a DataFrame for the annotations heatmap\n",
    "        gene_groups = df[['gene_id', 'gene_group']].drop_duplicates()\n",
    "        # Map gene groups to integer codes\n",
    "        gene_groups['group_code'] = gene_groups['gene_group'].factorize()[0]\n",
    "\n",
    "        # Create a DataFrame for the annotations heatmap\n",
    "        annotations_df = gene_groups[['gene_id', 'group_code', 'gene_group']].copy()\n",
    "        annotations_df['Group'] = 'Group'  # Dummy variable for y-axis\n",
    "\n",
    "        # Ensure 'gene_id' and 'Group' are categorical with the correct order\n",
    "        annotations_df['gene_id'] = pd.Categorical(annotations_df['gene_id'], categories=gene_ids_order, ordered=True)\n",
    "        annotations_df['Group'] = pd.Categorical(annotations_df['Group'], categories=['Group'], ordered=True)\n",
    "\n",
    "        # Create the annotations heatmap\n",
    "        annotations_heatmap = hv.HeatMap(\n",
    "            annotations_df,\n",
    "            kdims=['gene_id', 'Group'],\n",
    "            vdims=['group_code', 'gene_group']\n",
    "        )\n",
    "\n",
    "        # Customize the annotations heatmap\n",
    "        annotations_heatmap = annotations_heatmap.opts(\n",
    "            colorbar=False,\n",
    "            xaxis=None,\n",
    "            yaxis=None,\n",
    "            responsive=True,\n",
    "            cmap='glasbey_hv',\n",
    "            tools=['hover'],\n",
    "            toolbar=None,\n",
    "            height=50,\n",
    "            show_frame=False,\n",
    "            show_grid=False,\n",
    "        )\n",
    "\n",
    "        # # Create text labels for the gene groups\n",
    "        # # Calculate the center position of each gene group\n",
    "        # gene_group_positions = gene_groups.groupby('gene_group')['gene_id'].apply(list)\n",
    "        # text_annotations = []\n",
    "        # for group, gene_ids_in_group in gene_group_positions.items():\n",
    "        #     # Calculate the center position of the group\n",
    "        #     x_positions = [gene_ids_order.index(gene_id) for gene_id in gene_ids_in_group]\n",
    "        #     x_center = (min(x_positions) + max(x_positions)) / 2\n",
    "        #     text = hv.Text(gene_ids_order[int(x_center)], 'Group', group).opts(\n",
    "        #         text_align='right',\n",
    "        #         text_baseline='middle',\n",
    "        #         text_font_size='8pt',\n",
    "        #         text_color='black',\n",
    "        #         xaxis=None,\n",
    "        #         yaxis=None,\n",
    "        #         angle=90,\n",
    "        #     )\n",
    "        #     text_annotations.append(text)\n",
    "\n",
    "        # # Combine the text annotations\n",
    "        # text_overlay = hv.Overlay(text_annotations)\n",
    "\n",
    "        # # Overlay the text on the annotations heatmap\n",
    "        # annotations_plot = (annotations_heatmap * text_overlay).opts(\n",
    "        #     xaxis=None,\n",
    "        #     yaxis=None,\n",
    "        #     responsive=True,\n",
    "        #     height=50,\n",
    "        #     toolbar=None,\n",
    "        #     show_frame=False,\n",
    "        #     show_grid=False,\n",
    "        # )\n",
    "\n",
    "        # Stack the annotations_plot above the main plot\n",
    "        layout = hv.Layout([annotations_heatmap, points]).cols(1).opts(\n",
    "            opts.Layout(shared_axes=True)\n",
    "        )\n",
    "        return layout\n",
    "\n",
    "    else:\n",
    "        # No gene groups, proceed without annotations\n",
    "        return heatmap * points\n",
    "\n",
    "dp_data = compute_dotplot_data(adata.X, adata.obs['leiden_res_0.50'], adata.var_names, marker_genes, .1)\n",
    "plot_dotplot(dp_data, max_point_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a453426-4989-48d9-b33d-1a3bfc179499",
   "metadata": {},
   "source": [
    "### Without comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a73dc-a030-4396-a19b-ec4b71445aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "def compute_dotplot_data(expression, groupby, gene_names, markers, expression_cutoff):\n",
    "    \"\"\"\n",
    "    Compute data required for creating a dot plot, handling markers as a list or a dictionary,\n",
    "    and allowing for genes to appear in multiple groups.\n",
    "\n",
    "    Parameters:\n",
    "    - expression: n_cells x n_genes matrix (could be sparse)\n",
    "    - groupby: array of cluster assignments, length n_cells\n",
    "    - gene_names: list of gene names, length n_genes\n",
    "    - markers: either a list of gene names or a dictionary with keys as group labels and values as lists of gene names\n",
    "    - expression_cutoff: value used for binarizing expression (expression > cutoff)\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression', 'gene_group']\n",
    "    \"\"\"\n",
    "    # Ensure expression is CSR format for efficient operations\n",
    "    if not isinstance(expression, csr_matrix):\n",
    "        expression = csr_matrix(expression)\n",
    "\n",
    "    # Map gene names to indices\n",
    "    gene_name_to_idx = {gene: idx for idx, gene in enumerate(gene_names)}\n",
    "\n",
    "    # Initialize variables\n",
    "    gene_group_list = []\n",
    "\n",
    "    # Check if markers is a dictionary or a list\n",
    "    if isinstance(markers, dict):\n",
    "        # Markers is a dictionary with group labels\n",
    "        # Flatten markers dictionary to get list of (gene, group)\n",
    "        marker_genes = []\n",
    "        for group, genes in markers.items():\n",
    "            for gene in genes:\n",
    "                if gene in gene_name_to_idx:\n",
    "                    marker_genes.append((gene, group))\n",
    "\n",
    "        # Do not remove duplicates, keep genes as they appear\n",
    "        # Get the list of gene indices, allowing for duplicates\n",
    "        marker_indices = [gene_name_to_idx[gene] for gene, group in marker_genes]\n",
    "        marker_gene_names = [gene for gene, group in marker_genes]\n",
    "        gene_groups = [group for gene, group in marker_genes]\n",
    "\n",
    "    elif isinstance(markers, list):\n",
    "        # Markers is a list of gene names\n",
    "        marker_genes = [gene for gene in markers if gene in gene_name_to_idx]\n",
    "\n",
    "        # Remove duplicates while preserving order\n",
    "        marker_genes = list(dict.fromkeys(marker_genes))\n",
    "\n",
    "        # Get indices of marker genes\n",
    "        marker_indices = [gene_name_to_idx[gene] for gene in marker_genes]\n",
    "        marker_gene_names = marker_genes\n",
    "        gene_groups = [None] * len(marker_gene_names)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Markers must be a list or a dictionary.\")\n",
    "\n",
    "    # Convert groupby to numpy array if it's not already\n",
    "    groupby = np.array(groupby)\n",
    "    clusters = np.unique(groupby)\n",
    "\n",
    "    # Check if all clusters are numeric\n",
    "    clusters_series = pd.Series(clusters)\n",
    "    clusters_numeric = pd.to_numeric(clusters_series, errors='coerce')\n",
    "\n",
    "    if clusters_numeric.isnull().any():\n",
    "        convert_cluster_to_numeric = False\n",
    "    else:\n",
    "        convert_cluster_to_numeric = True\n",
    "\n",
    "    # Initialize list to collect results\n",
    "    results = []\n",
    "\n",
    "    # For each marker gene (could be duplicated)\n",
    "    for gene_idx, gene_name, gene_group in zip(marker_indices, marker_gene_names, gene_groups):\n",
    "        # Get the expression vector for this gene\n",
    "        gene_expression = expression[:, gene_idx]\n",
    "\n",
    "        # Binarize the expression data using the expression_cutoff\n",
    "        gene_expression_binarized = gene_expression.copy()\n",
    "        gene_expression_binarized.data = (gene_expression_binarized.data > expression_cutoff).astype(int)\n",
    "\n",
    "        # For each cluster\n",
    "        for cluster in clusters:\n",
    "            # Get indices of cells in the current cluster\n",
    "            cluster_mask = groupby == cluster\n",
    "            cluster_cell_indices = np.where(cluster_mask)[0]\n",
    "\n",
    "            # Number of cells in the cluster\n",
    "            n_cells_in_cluster = len(cluster_cell_indices)\n",
    "\n",
    "            # Subset the expression data to cells in the cluster\n",
    "            X_cluster = gene_expression[cluster_cell_indices]\n",
    "            X_cluster_binarized = gene_expression_binarized[cluster_cell_indices]\n",
    "\n",
    "            # Compute the sum of binarized expression (number of cells expressing the gene)\n",
    "            expressing_cells = X_cluster_binarized.sum()\n",
    "\n",
    "            # Compute percentage of cells expressing the gene\n",
    "            percentage = (expressing_cells / n_cells_in_cluster) * 100  # Percentage\n",
    "\n",
    "            # Compute mean expression per gene over all cells in cluster\n",
    "            total_expression = X_cluster.sum()\n",
    "            mean_expression = total_expression / n_cells_in_cluster  # Mean expression\n",
    "\n",
    "            # Collect results into DataFrames\n",
    "            cluster_results = pd.DataFrame({\n",
    "                'gene': [gene_name],\n",
    "                'cluster': [cluster],\n",
    "                'percentage': [percentage],\n",
    "                'mean_expression': [mean_expression],\n",
    "                'gene_group': [gene_group]\n",
    "            })\n",
    "            results.append(cluster_results)\n",
    "\n",
    "    # Concatenate results from all clusters and all genes\n",
    "    df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    # Convert 'cluster' column to numeric if all clusters are numeric\n",
    "    if convert_cluster_to_numeric:\n",
    "        df['cluster'] = pd.to_numeric(df['cluster'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_dotplot(df, max_point_size=40):\n",
    "    \"\"\"\n",
    "    Create a dot plot from the DataFrame output by compute_dotplot_data,\n",
    "    handling genes that appear multiple times due to being in multiple groups.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression', 'gene_group']\n",
    "    - max_point_size: Maximum size for the dots representing 100% percentage.\n",
    "\n",
    "    Returns:\n",
    "    - plot: Holoviews object representing the dot plot.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Create a unique identifier for each gene entry\n",
    "    df = df.copy()\n",
    "    df['gene_id'] = df.apply(\n",
    "        lambda row: f\"{row['gene']} ({row['gene_group']})\" if pd.notnull(row['gene_group']) else row['gene'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Map percentage to point sizes\n",
    "    df['size'] = (df['percentage'] / df['percentage'].max()) * max_point_size\n",
    "\n",
    "    # Normalize mean_expression for color mapping\n",
    "    df['mean_expression_normalized'] = df['mean_expression'] / df['mean_expression'].max()\n",
    "\n",
    "    # Ensure 'gene_id' is a categorical variable with the correct order\n",
    "    gene_ids_order = df['gene_id'].drop_duplicates().tolist()\n",
    "    df['gene_id'] = pd.Categorical(df['gene_id'], categories=gene_ids_order, ordered=True)\n",
    "\n",
    "    # Extract sorted unique cluster values\n",
    "    cluster_values = sorted(df['cluster'].unique())\n",
    "\n",
    "    # Determine ylim to make Y-axis tight to data extents\n",
    "    min_cluster = min(cluster_values)\n",
    "    max_cluster = max(cluster_values)\n",
    "    ylim = (max_cluster + 0.5, min_cluster - 0.5)\n",
    "\n",
    "    # Create yticks as a list of tuples (position, label)\n",
    "    yticks = [(cluster, str(cluster)) for cluster in cluster_values]\n",
    "\n",
    "    # Create the main points plot\n",
    "    points = hv.Points(\n",
    "        df,\n",
    "        kdims=['gene_id', 'cluster'],\n",
    "        vdims=['mean_expression_normalized', 'size', 'percentage', 'mean_expression', 'gene_group']\n",
    "    )\n",
    "\n",
    "    # Customize the points plot\n",
    "    points = points.opts(\n",
    "        xrotation=90,\n",
    "        color='mean_expression_normalized',\n",
    "        cmap='Reds',\n",
    "        size='size',\n",
    "        line_color='black',\n",
    "        line_alpha=0.1,\n",
    "        marker='o',\n",
    "        tools=['hover'],\n",
    "        colorbar=True,\n",
    "        min_height=400,\n",
    "        responsive=True,\n",
    "        xlabel='Gene',\n",
    "        ylabel='Cluster',\n",
    "        invert_yaxis=False,\n",
    "        show_legend=False,\n",
    "        yticks=yticks,\n",
    "        ylim=ylim,\n",
    "    )\n",
    "\n",
    "    if 'gene_group' in df.columns:\n",
    "        # Create a DataFrame for the annotations heatmap\n",
    "        gene_groups = df[['gene_id', 'gene_group']].drop_duplicates()\n",
    "        # Map gene groups to integer codes\n",
    "        gene_groups['group_code'] = gene_groups['gene_group'].factorize()[0]\n",
    "\n",
    "        # Create a DataFrame for the annotations heatmap\n",
    "        annotations_df = gene_groups[['gene_id', 'group_code', 'gene_group']].copy()\n",
    "        annotations_df['Group'] = 'Group'  # Dummy variable for y-axis\n",
    "\n",
    "        # Ensure 'gene_id' and 'Group' are categorical with the correct order\n",
    "        annotations_df['gene_id'] = pd.Categorical(annotations_df['gene_id'], categories=gene_ids_order, ordered=True)\n",
    "        annotations_df['Group'] = pd.Categorical(annotations_df['Group'], categories=['Group'], ordered=True)\n",
    "\n",
    "        # Create the annotations heatmap\n",
    "        annotations_heatmap = hv.HeatMap(\n",
    "            annotations_df,\n",
    "            kdims=['gene_id', 'Group'],\n",
    "            vdims=['group_code', 'gene_group']\n",
    "        )\n",
    "\n",
    "        # Customize the annotations heatmap\n",
    "        annotations_heatmap = annotations_heatmap.opts(\n",
    "            colorbar=False,\n",
    "            xaxis=None,\n",
    "            yaxis=None,\n",
    "            responsive=True,\n",
    "            cmap='glasbey_hv',\n",
    "            tools=['hover'],\n",
    "            toolbar=None,\n",
    "            height=50,\n",
    "            show_frame=False,\n",
    "            show_grid=False,\n",
    "        )\n",
    "\n",
    "        # Stack the annotations_heatmap above the main plot\n",
    "        layout = hv.Layout([annotations_heatmap, points]).cols(1).opts(\n",
    "            opts.Layout(shared_axes=True)\n",
    "        )\n",
    "        return layout\n",
    "\n",
    "    else:\n",
    "        # No gene groups, proceed without annotations\n",
    "        return points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328d268-1286-4eaf-b8c1-359813ca0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_data = compute_dotplot_data(adata.X, adata.obs['leiden_res_0.50'], adata.var_names, marker_genes, .1)\n",
    "plot_dotplot(dp_data, max_point_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d017977f-3f15-4419-adcf-6832f745850b",
   "metadata": {},
   "source": [
    "### With dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e1f51-699b-4eb4-895f-0231705fc6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import pdist\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import panel as pn\n",
    "pn.extension('gridstack')\n",
    "hv.extension('bokeh')\n",
    "\n",
    "def compute_dotplot_data(expression, groupby, gene_names, markers, expression_cutoff):\n",
    "    \"\"\"\n",
    "    Compute data required for creating a dot plot, handling markers as a list or a dictionary,\n",
    "    and allowing for genes to appear in multiple groups.\n",
    "\n",
    "    Parameters:\n",
    "    - expression: n_cells x n_genes matrix (could be sparse)\n",
    "    - groupby: array of cluster assignments, length n_cells\n",
    "    - gene_names: list of gene names, length n_genes\n",
    "    - markers: either a list of gene names or a dictionary with keys as group labels and values as lists of gene names\n",
    "    - expression_cutoff: value used for binarizing expression (expression > cutoff)\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression', 'gene_group']\n",
    "    \"\"\"\n",
    "    # Ensure expression is CSR format for efficient operations\n",
    "    if not isinstance(expression, csr_matrix):\n",
    "        expression = csr_matrix(expression)\n",
    "\n",
    "    # Map gene names to indices\n",
    "    gene_name_to_idx = {gene: idx for idx, gene in enumerate(gene_names)}\n",
    "\n",
    "    # Initialize variables\n",
    "    gene_group_list = []\n",
    "\n",
    "    # Check if markers is a dictionary or a list\n",
    "    if isinstance(markers, dict):\n",
    "        # Markers is a dictionary with group labels\n",
    "        # Flatten markers dictionary to get list of (gene, group)\n",
    "        marker_genes = []\n",
    "        for group, genes in markers.items():\n",
    "            for gene in genes:\n",
    "                if gene in gene_name_to_idx:\n",
    "                    marker_genes.append((gene, group))\n",
    "\n",
    "        # Do not remove duplicates, keep genes as they appear\n",
    "        # Get the list of gene indices, allowing for duplicates\n",
    "        marker_indices = [gene_name_to_idx[gene] for gene, group in marker_genes]\n",
    "        marker_gene_names = [gene for gene, group in marker_genes]\n",
    "        gene_groups = [group for gene, group in marker_genes]\n",
    "\n",
    "    elif isinstance(markers, list):\n",
    "        # Markers is a list of gene names\n",
    "        marker_genes = [gene for gene in markers if gene in gene_name_to_idx]\n",
    "\n",
    "        # Remove duplicates while preserving order\n",
    "        marker_genes = list(dict.fromkeys(marker_genes))\n",
    "\n",
    "        # Get indices of marker genes\n",
    "        marker_indices = [gene_name_to_idx[gene] for gene in marker_genes]\n",
    "        marker_gene_names = marker_genes\n",
    "        gene_groups = [None] * len(marker_gene_names)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Markers must be a list or a dictionary.\")\n",
    "\n",
    "    # Convert groupby to numpy array if it's not already\n",
    "    groupby = np.array(groupby)\n",
    "    clusters = np.unique(groupby)\n",
    "\n",
    "    # Check if all clusters are numeric\n",
    "    clusters_series = pd.Series(clusters)\n",
    "    clusters_numeric = pd.to_numeric(clusters_series, errors='coerce')\n",
    "\n",
    "    if clusters_numeric.isnull().any():\n",
    "        convert_cluster_to_numeric = False\n",
    "    else:\n",
    "        convert_cluster_to_numeric = True\n",
    "\n",
    "    # Initialize list to collect results\n",
    "    results = []\n",
    "\n",
    "    # For each marker gene (could be duplicated)\n",
    "    for gene_idx, gene_name, gene_group in zip(marker_indices, marker_gene_names, gene_groups):\n",
    "        # Get the expression vector for this gene\n",
    "        gene_expression = expression[:, gene_idx]\n",
    "\n",
    "        # Binarize the expression data using the expression_cutoff\n",
    "        gene_expression_binarized = gene_expression.copy()\n",
    "        gene_expression_binarized.data = (gene_expression_binarized.data > expression_cutoff).astype(int)\n",
    "\n",
    "        # For each cluster\n",
    "        for cluster in clusters:\n",
    "            # Get indices of cells in the current cluster\n",
    "            cluster_mask = groupby == cluster\n",
    "            cluster_cell_indices = np.where(cluster_mask)[0]\n",
    "\n",
    "            # Number of cells in the cluster\n",
    "            n_cells_in_cluster = len(cluster_cell_indices)\n",
    "\n",
    "            # Subset the expression data to cells in the cluster\n",
    "            X_cluster = gene_expression[cluster_cell_indices]\n",
    "            X_cluster_binarized = gene_expression_binarized[cluster_cell_indices]\n",
    "\n",
    "            # Compute the sum of binarized expression (number of cells expressing the gene)\n",
    "            expressing_cells = X_cluster_binarized.sum()\n",
    "\n",
    "            # Compute percentage of cells expressing the gene\n",
    "            percentage = (expressing_cells / n_cells_in_cluster) * 100  # Percentage\n",
    "\n",
    "            # Compute mean expression per gene over all cells in cluster\n",
    "            total_expression = X_cluster.sum()\n",
    "            mean_expression = total_expression / n_cells_in_cluster  # Mean expression\n",
    "\n",
    "            # Collect results into DataFrames\n",
    "            cluster_results = pd.DataFrame({\n",
    "                'gene': [gene_name],\n",
    "                'cluster': [cluster],\n",
    "                'percentage': [percentage],\n",
    "                'mean_expression': [mean_expression],\n",
    "                'gene_group': [gene_group]\n",
    "            })\n",
    "            results.append(cluster_results)\n",
    "\n",
    "    # Concatenate results from all clusters and all genes\n",
    "    df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    # Convert 'cluster' column to numeric if all clusters are numeric\n",
    "    if convert_cluster_to_numeric:\n",
    "        df['cluster'] = pd.to_numeric(df['cluster'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_dotplot(df, max_point_size=40):\n",
    "    \"\"\"\n",
    "    Create a dot plot from the DataFrame output by compute_dotplot_data,\n",
    "    handling genes that appear multiple times due to being in multiple groups,\n",
    "    and adding a dendrogram to the right of the main plot.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns ['gene', 'cluster', 'percentage', 'mean_expression', 'gene_group']\n",
    "    - max_point_size: Maximum size for the dots representing 100% percentage.\n",
    "\n",
    "    Returns:\n",
    "    - plot: Holoviews object representing the dot plot with a dendrogram.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "    from scipy.spatial.distance import pdist\n",
    "    import holoviews as hv\n",
    "\n",
    "    # Create a unique identifier for each gene entry\n",
    "    df = df.copy()\n",
    "    df['gene_id'] = df.apply(\n",
    "        lambda row: f\"{row['gene']} ({row['gene_group']})\" if pd.notnull(row['gene_group']) else row['gene'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Map percentage to point sizes\n",
    "    df['size'] = (df['percentage'] / df['percentage'].max()) * max_point_size\n",
    "\n",
    "    # Normalize mean_expression for color mapping\n",
    "    df['mean_expression_normalized'] = df['mean_expression'] / df['mean_expression'].max()\n",
    "\n",
    "    # Ensure 'gene_id' is a categorical variable with the correct order\n",
    "    gene_ids_order = df['gene_id'].drop_duplicates().tolist()\n",
    "    df['gene_id'] = pd.Categorical(df['gene_id'], categories=gene_ids_order, ordered=True)\n",
    "\n",
    "    # Create the cluster-gene matrix for clustering\n",
    "    cluster_gene_matrix = df.pivot_table(index='cluster', columns='gene_id', values='mean_expression', fill_value=0)\n",
    "\n",
    "    # Perform hierarchical clustering on clusters\n",
    "    # Compute the distance matrix\n",
    "    X = cluster_gene_matrix.values\n",
    "    cluster_dist = pdist(X, metric='euclidean')\n",
    "\n",
    "    # Perform hierarchical clustering\n",
    "    cluster_linkage = linkage(cluster_dist, method='average')\n",
    "\n",
    "    # Create a dendrogram plot without plotting\n",
    "    dendro_data = dendrogram(cluster_linkage, labels=cluster_gene_matrix.index, no_plot=True)\n",
    "\n",
    "    # Get the order of clusters from dendrogram\n",
    "    clusters_ordered = dendro_data['ivl']\n",
    "\n",
    "    # Update df['cluster'] to be categorical with the new order\n",
    "    df['cluster'] = pd.Categorical(df['cluster'], categories=clusters_ordered, ordered=True)\n",
    "\n",
    "    # Map cluster labels to positions (for y-axis)\n",
    "    cluster_positions = {cluster: pos for pos, cluster in enumerate(clusters_ordered)}\n",
    "    df['cluster_pos'] = df['cluster'].map(cluster_positions)\n",
    "\n",
    "    # Create yticks as a list of tuples (position, label)\n",
    "    # yticks = [(pos, str(cluster)) for pos, cluster in enumerate(clusters_ordered)]\n",
    "\n",
    "    # Extract sorted unique cluster values\n",
    "    cluster_values = sorted(df['cluster'].unique())\n",
    "\n",
    "    # Determine ylim to make Y-axis tight to data extents\n",
    "    min_cluster = min(cluster_values)\n",
    "    max_cluster = max(cluster_values)\n",
    "    ylim = (max_cluster + 0.5, min_cluster - 0.5)\n",
    "\n",
    "    # Create yticks as a list of tuples (position, label)\n",
    "    yticks = [(cluster, str(cluster)) for cluster in cluster_values]\n",
    "\n",
    "    # Create the main points plot\n",
    "    points = hv.Points(\n",
    "        df,\n",
    "        kdims=['gene_id', 'cluster_pos'],\n",
    "        vdims=['mean_expression_normalized', 'size', 'percentage', 'mean_expression', 'gene_group']\n",
    "    )\n",
    "\n",
    "    # Customize the points plot\n",
    "    points = points.opts(\n",
    "        xrotation=90,\n",
    "        color='mean_expression_normalized',\n",
    "        cmap='Reds',\n",
    "        size='size',\n",
    "        line_color='black',\n",
    "        line_alpha=0.1,\n",
    "        marker='o',\n",
    "        tools=['hover'],\n",
    "        colorbar=True,\n",
    "        width=1000,\n",
    "        frame_height=400,\n",
    "        # responsive=True,\n",
    "        xlabel='Gene',\n",
    "        ylabel='Cluster',\n",
    "        invert_yaxis=False,\n",
    "        show_legend=False,\n",
    "        yticks=yticks,\n",
    "        ylim=ylim,\n",
    "    )\n",
    "\n",
    "    if 'gene_group' in df.columns:\n",
    "        # Create a DataFrame for the annotations heatmap\n",
    "        gene_groups = df[['gene_id', 'gene_group']].drop_duplicates()\n",
    "        # Map gene groups to integer codes\n",
    "        gene_groups['group_code'] = gene_groups['gene_group'].factorize()[0]\n",
    "\n",
    "        # Create a DataFrame for the annotations heatmap\n",
    "        annotations_df = gene_groups[['gene_id', 'group_code', 'gene_group']].copy()\n",
    "        annotations_df['Group'] = 'Group'  # Dummy variable for y-axis\n",
    "\n",
    "        # Ensure 'gene_id' and 'Group' are categorical with the correct order\n",
    "        annotations_df['gene_id'] = pd.Categorical(annotations_df['gene_id'], categories=gene_ids_order, ordered=True)\n",
    "        annotations_df['Group'] = pd.Categorical(annotations_df['Group'], categories=['Group'], ordered=True)\n",
    "\n",
    "        # Create the annotations heatmap\n",
    "        annotations_heatmap = hv.HeatMap(\n",
    "            annotations_df,\n",
    "            kdims=['gene_id', 'Group'],\n",
    "            vdims=['group_code', 'gene_group']\n",
    "        )\n",
    "\n",
    "        # Customize the annotations heatmap\n",
    "        annotations_heatmap = annotations_heatmap.opts(\n",
    "            colorbar=False,\n",
    "            xaxis=None,\n",
    "            yaxis=None,\n",
    "            responsive=False,\n",
    "            width=600,\n",
    "            cmap='glasbey_hv',\n",
    "            tools=['hover'],\n",
    "            toolbar=None,\n",
    "            height=50,\n",
    "            show_frame=False,\n",
    "            show_grid=False,\n",
    "        )\n",
    "\n",
    "        # Stack the annotations_heatmap above the main plot\n",
    "        main_plot = hv.Layout([annotations_heatmap, hv.Empty(), points]).cols(2).opts(\n",
    "            opts.Layout(shared_axes=True)\n",
    "        )\n",
    "    else:\n",
    "        main_plot = points\n",
    "\n",
    "    # Map leaf positions to cluster positions\n",
    "    leaf_positions = {int(leaf_id): cluster_positions[clusters_ordered[int(leaf_id)]] for leaf_id in dendro_data['leaves']}\n",
    "\n",
    "    # Adjust coordinates to match the cluster positions\n",
    "    dendro_paths = []\n",
    "    icoord = np.array(dendro_data['dcoord'])  # Swapped\n",
    "    dcoord = np.array(dendro_data['icoord'])  # Swapped\n",
    "\n",
    "    for xs, ys in zip(icoord, dcoord):\n",
    "        ys_new = []\n",
    "        for y in ys:\n",
    "            if y % 10 == 5.0:\n",
    "                # Leaf node\n",
    "                leaf_id = int((y - 5.0) / 10.0)\n",
    "                ys_new.append(leaf_positions[leaf_id])\n",
    "            else:\n",
    "                # Internal node\n",
    "                ys_new.append(y / max(dcoord.flatten()) * (len(clusters_ordered) - 1))\n",
    "        dendro_paths.append(np.column_stack([xs, ys_new]))\n",
    "\n",
    "    # Create the dendrogram plot\n",
    "    dendrogram_plot = hv.Path(dendro_paths, ['Distance', 'Cluster'])\n",
    "\n",
    "    # Customize dendrogram\n",
    "    dendrogram_plot = dendrogram_plot.opts(\n",
    "        width=200,\n",
    "        frame_height=400,\n",
    "        xlabel='',\n",
    "        # ylabel='',\n",
    "        invert_yaxis=False,\n",
    "        xaxis=None,\n",
    "        yaxis='right',\n",
    "        # yaxis=None,\n",
    "        show_frame=False,\n",
    "        # show_grid=False,\n",
    "        fontsize={'labels': '8pt'},\n",
    "        tools=['hover'],\n",
    "        yticks=yticks,\n",
    "        ylim=ylim,\n",
    "        \n",
    "    )\n",
    "\n",
    "    return (points + dendrogram_plot).opts(shared_axes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd108bd-4204-43b0-b33e-aaca4af575db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_data = compute_dotplot_data(adata.X, adata.obs['leiden_res_0.50'], adata.var_names, marker_genes, 0.1)\n",
    "plot = plot_dotplot(dp_data, max_point_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd03f01-b884-4b13-a5f5-6a7756198f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255b635-bf31-48ae-8d60-a04d2c1689a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "mystnb": {
   "execution_mode": "off"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
